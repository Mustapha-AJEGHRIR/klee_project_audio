{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: No metadata found in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: No metadata found in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages\u001b[0m\u001b[33m\n",
      "\u001b[0mkeras                         2.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip list |grep keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.7.0\n",
      "  Using cached keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/numpy-1.21.5.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.8.0\n",
      "    Uninstalling keras-2.8.0:\n",
      "      Successfully uninstalled keras-2.8.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.7.0 requires numpy>=1.14.5, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-2.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install keras==2.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         # Currently, memory growth needs to be the same across GPUs\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#         logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#     except RuntimeError as e:\n",
    "#         # Memory growth must be set before GPUs have been initialized\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.insert(0,'..')\n",
    "from src.load_dataset_fft_aug import get_splitter_dataloaders_fft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    layers.Conv1D(32, kernel_size=3, activation=\"relu\", input_shape=(201, 498)),\n",
    "    layers.MaxPool1D(pool_size=4, strides=4),\n",
    "\n",
    "    layers.Conv1D(64, kernel_size=3, activation=\"relu\"),\n",
    "    layers.MaxPool1D(pool_size=2, strides=2),\n",
    "\n",
    "    layers.Conv1D(64, kernel_size=3, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.LSTM(units=40, return_sequences=True),\n",
    "    \n",
    "    layers.MaxPool1D(pool_size=2, strides=2),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(2)\n",
    "    ])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "# L1 loss\n",
    "model.compile(optimizer=optimizer,\n",
    "            loss=\"mae\",\n",
    "            metrics=[\"mae\"]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = tf.random.normal([1, 201, 498])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.3850 - mae: 0.3850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3cd0680b20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x, y=tf.constant([[0.0, 0.0]]), epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching noise: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 819/819 [00:04<00:00, 176.63it/s]\n",
      "Caching dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4576/4576 [00:25<00:00, 177.56it/s]\n",
      "Caching noise: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:01<00:00, 188.04it/s]\n",
      "Caching dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1144/1144 [00:06<00:00, 180.60it/s]\n"
     ]
    }
   ],
   "source": [
    "_, _, train, val = get_splitter_dataloaders_fft(noise_attenuation=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a generator for the dataset in order to feed it to the model directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = []\n",
    "# for i in range(len(train)):\n",
    "#     y_train.append(train[i][1])\n",
    "\n",
    "# y_val = []\n",
    "# for i in range(len(val)):\n",
    "#     y_val.append(val[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    for i in range(len(train)):\n",
    "        instance = train[i]\n",
    "        yield instance[0], instance[1]\n",
    "        \n",
    "def val_generator():\n",
    "    for i in range(len(val)):\n",
    "        instance = val[i]\n",
    "        yield instance[0], instance[1]\n",
    "        \n",
    "BATCH_SIZE = 64\n",
    "train_dataset = tf.data.Dataset.from_generator(train_generator, output_types=(tf.float32, tf.float32), output_shapes=((201, 498), (2,))).padded_batch(BATCH_SIZE)\n",
    "val_dataset = tf.data.Dataset.from_generator(val_generator, output_types=(tf.float32, tf.float32), output_shapes=((201, 498), (2,))).padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model ðŸ˜ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "72/72 [==============================] - 7s 94ms/step - loss: 1.6679 - mae: 1.6679 - val_loss: 1.3256 - val_mae: 1.3256\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 1.2206 - mae: 1.2206 - val_loss: 1.1131 - val_mae: 1.1131\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 1.1215 - mae: 1.1215 - val_loss: 0.9988 - val_mae: 0.9988\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 1.0530 - mae: 1.0530 - val_loss: 0.9864 - val_mae: 0.9864\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 1.0116 - mae: 1.0116 - val_loss: 0.9055 - val_mae: 0.9055\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 6s 82ms/step - loss: 0.9617 - mae: 0.9617 - val_loss: 0.8653 - val_mae: 0.8653\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.9363 - mae: 0.9363 - val_loss: 0.8529 - val_mae: 0.8529\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.8873 - mae: 0.8873 - val_loss: 0.7791 - val_mae: 0.7791\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.8821 - mae: 0.8821 - val_loss: 0.7384 - val_mae: 0.7384\n",
      "Epoch 10/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.8313 - mae: 0.8313 - val_loss: 0.7192 - val_mae: 0.7192\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - 6s 86ms/step - loss: 0.8221 - mae: 0.8221 - val_loss: 0.7382 - val_mae: 0.7382\n",
      "Epoch 12/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.8259 - mae: 0.8259 - val_loss: 0.7162 - val_mae: 0.7162\n",
      "Epoch 13/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.7939 - mae: 0.7939 - val_loss: 0.7344 - val_mae: 0.7344\n",
      "Epoch 14/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.8052 - mae: 0.8052 - val_loss: 0.7415 - val_mae: 0.7415\n",
      "Epoch 15/50\n",
      "72/72 [==============================] - 6s 79ms/step - loss: 0.7789 - mae: 0.7789 - val_loss: 0.6980 - val_mae: 0.6980\n",
      "Epoch 16/50\n",
      "72/72 [==============================] - 6s 79ms/step - loss: 0.7746 - mae: 0.7746 - val_loss: 0.7072 - val_mae: 0.7072\n",
      "Epoch 17/50\n",
      "72/72 [==============================] - 6s 79ms/step - loss: 0.7758 - mae: 0.7758 - val_loss: 0.7511 - val_mae: 0.7511\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.7570 - mae: 0.7570 - val_loss: 0.7007 - val_mae: 0.7007\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.7611 - mae: 0.7611 - val_loss: 0.7038 - val_mae: 0.7038\n",
      "Epoch 20/50\n",
      "72/72 [==============================] - 6s 79ms/step - loss: 0.7652 - mae: 0.7652 - val_loss: 0.6804 - val_mae: 0.6804\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.7578 - mae: 0.7578 - val_loss: 0.7023 - val_mae: 0.7023\n",
      "Epoch 22/50\n",
      "72/72 [==============================] - 6s 79ms/step - loss: 0.7497 - mae: 0.7497 - val_loss: 0.6659 - val_mae: 0.6659\n",
      "Epoch 23/50\n",
      "72/72 [==============================] - 6s 79ms/step - loss: 0.7404 - mae: 0.7404 - val_loss: 0.6714 - val_mae: 0.6714\n",
      "Epoch 24/50\n",
      "72/72 [==============================] - 6s 79ms/step - loss: 0.7390 - mae: 0.7390 - val_loss: 0.6690 - val_mae: 0.6690\n",
      "Epoch 25/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.7457 - mae: 0.7457 - val_loss: 0.6647 - val_mae: 0.6647\n",
      "Epoch 26/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.7350 - mae: 0.7350 - val_loss: 0.7247 - val_mae: 0.7247\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.7411 - mae: 0.7411 - val_loss: 0.6761 - val_mae: 0.6761\n",
      "Epoch 28/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.7312 - mae: 0.7312 - val_loss: 0.6643 - val_mae: 0.6643\n",
      "Epoch 29/50\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.7204 - mae: 0.7204 - val_loss: 0.6832 - val_mae: 0.6832\n",
      "Epoch 30/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.7244 - mae: 0.7244 - val_loss: 0.6424 - val_mae: 0.6424\n",
      "Epoch 31/50\n",
      "72/72 [==============================] - 6s 79ms/step - loss: 0.7376 - mae: 0.7376 - val_loss: 0.6595 - val_mae: 0.6595\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.7157 - mae: 0.7157 - val_loss: 0.6640 - val_mae: 0.6640\n",
      "Epoch 33/50\n",
      "72/72 [==============================] - 6s 79ms/step - loss: 0.7195 - mae: 0.7195 - val_loss: 0.6565 - val_mae: 0.6565\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - 6s 82ms/step - loss: 0.7142 - mae: 0.7142 - val_loss: 0.6628 - val_mae: 0.6628\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.7224 - mae: 0.7224 - val_loss: 0.7096 - val_mae: 0.7096\n",
      "Epoch 36/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.7049 - mae: 0.7049 - val_loss: 0.6444 - val_mae: 0.6444\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - 6s 82ms/step - loss: 0.7132 - mae: 0.7132 - val_loss: 0.6587 - val_mae: 0.6587\n",
      "Epoch 38/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.7021 - mae: 0.7021 - val_loss: 0.6804 - val_mae: 0.6804\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.7018 - mae: 0.7018 - val_loss: 0.6450 - val_mae: 0.6450\n",
      "Epoch 40/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.7047 - mae: 0.7047 - val_loss: 0.6475 - val_mae: 0.6475\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - 6s 79ms/step - loss: 0.7011 - mae: 0.7011 - val_loss: 0.6802 - val_mae: 0.6802\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.7036 - mae: 0.7036 - val_loss: 0.6555 - val_mae: 0.6555\n",
      "Epoch 43/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.6973 - mae: 0.6973 - val_loss: 0.6670 - val_mae: 0.6670\n",
      "Epoch 44/50\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.6805 - mae: 0.6805 - val_loss: 0.6185 - val_mae: 0.6185\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.6800 - mae: 0.6800 - val_loss: 0.6325 - val_mae: 0.6325\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.6862 - mae: 0.6862 - val_loss: 0.6452 - val_mae: 0.6452\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.7007 - mae: 0.7007 - val_loss: 0.6502 - val_mae: 0.6502\n",
      "Epoch 48/50\n",
      "72/72 [==============================] - 6s 79ms/step - loss: 0.6841 - mae: 0.6841 - val_loss: 0.6257 - val_mae: 0.6257\n",
      "Epoch 49/50\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.6904 - mae: 0.6904 - val_loss: 0.6464 - val_mae: 0.6464\n",
      "Epoch 50/50\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.6850 - mae: 0.6850 - val_loss: 0.6269 - val_mae: 0.6269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c6c4edaf0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=50, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.6581 - mae: 0.6581\n",
      "Epoch 2/2\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 0.6253 - mae: 0.6253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c6c484940>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(val_dataset, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/tf_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved/tf_model/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3cdc082880> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "save_path = \"saved/tf_model\"\n",
    "# tf.saved_model.save(model, save_path)\n",
    "\n",
    "run_model = tf.function(lambda x: model(x))\n",
    "BATCH_SIZE = 1\n",
    "FREQS = 201\n",
    "TIME_STEPS = 498\n",
    "concrete_func = run_model.get_concrete_function(\n",
    "    tf.TensorSpec([BATCH_SIZE, FREQS, TIME_STEPS], model.inputs[0].dtype))\n",
    "model.save(save_path, save_format=\"tf\", signatures=concrete_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tinify model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated count of arithmetic ops: 20.144 M  ops, equivalently 10.072 M  MACs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "97776"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(save_path)\n",
    "\n",
    "save_path_tflite = os.path.basename(save_path) + \".tflite\"\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "tflite_model_file = pathlib.Path(save_path_tflite)\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is for testing the model without rerunning the cells above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"saved/tf_model\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42965645,  0.11463061], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "interpreter.set_tensor(input_index, tf.random.normal([1, 201, 498]))\n",
    "\n",
    "interpreter.invoke()\n",
    "output = interpreter.tensor(output_index)()[0]\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "00f8b6a529d4a87e56a80115d87724b6edf8720afa22f229ab58fd82e4e251b2"
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
