{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.7.0\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.insert(0,'..')\n",
    "from src.load_dataset_fft_aug import get_splitter_dataloaders_fft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 28, 28, 32])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Conv2D(filters=32,\n",
    "            kernel_size=3,\n",
    "            strides=1,\n",
    "            padding='same',\n",
    "            activation='relu')(tf.random.normal([1, 28, 28, 1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 28, 40])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.LSTM(units=40, return_sequences=True)(tf.random.normal([1, 28, 280])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    layers.Conv1D(32, kernel_size=3, activation=\"relu\", input_shape=(201, 498)),\n",
    "    layers.MaxPool1D(pool_size=4, strides=4),\n",
    "\n",
    "    layers.Conv1D(64, kernel_size=3, activation=\"relu\"),\n",
    "    layers.MaxPool1D(pool_size=2, strides=2),\n",
    "\n",
    "    layers.Conv1D(64, kernel_size=3, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.LSTM(units=40, return_sequences=True),\n",
    "    \n",
    "    layers.MaxPool1D(pool_size=2, strides=2),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(2)\n",
    "    ])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "# L1 loss\n",
    "model.compile(optimizer=optimizer,\n",
    "            loss=\"mae\",\n",
    "            metrics=[\"mae\"]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tf.constant([0.0, 0.0])\n",
    "x = tf.random.normal([1, 201, 498])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 0.2470 - mae: 0.2470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f09867339d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x, y=tf.constant([[0.0, 0.0]]), epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching noise: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 819/819 [00:06<00:00, 118.90it/s]\n",
      "Caching dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4576/4576 [01:09<00:00, 65.89it/s]\n",
      "Caching noise: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 221/221 [00:02<00:00, 95.13it/s] \n",
      "Caching dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1144/1144 [00:16<00:00, 68.05it/s]\n"
     ]
    }
   ],
   "source": [
    "_, _, train, val = get_splitter_dataloaders_fft(noise_attenuation=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a generator for the dataset in order to feed it to the model directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = []\n",
    "# for i in range(len(train)):\n",
    "#     y_train.append(train[i][1])\n",
    "\n",
    "# y_val = []\n",
    "# for i in range(len(val)):\n",
    "#     y_val.append(val[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    for i in range(len(train)):\n",
    "        instance = train[i]\n",
    "        yield instance[0], instance[1]\n",
    "        \n",
    "def val_generator():\n",
    "    for i in range(len(val)):\n",
    "        instance = val[i]\n",
    "        yield instance[0], instance[1]\n",
    "        \n",
    "BATCH_SIZE = 16\n",
    "train_dataset = tf.data.Dataset.from_generator(train_generator, output_types=(tf.float32, tf.float32), output_shapes=((201, 498), (2,))).padded_batch(BATCH_SIZE)\n",
    "val_dataset = tf.data.Dataset.from_generator(val_generator, output_types=(tf.float32, tf.float32), output_shapes=((201, 498), (2,))).padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model ðŸ˜ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "286/286 [==============================] - 18s 59ms/step - loss: 1.4965 - mae: 1.4965 - val_loss: 1.1138 - val_mae: 1.1138\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 15s 52ms/step - loss: 1.3093 - mae: 1.3093 - val_loss: 0.9861 - val_mae: 0.9861\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 14s 49ms/step - loss: 1.2484 - mae: 1.2484 - val_loss: 0.8515 - val_mae: 0.8515\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 15s 51ms/step - loss: 1.1988 - mae: 1.1988 - val_loss: 0.8619 - val_mae: 0.8619\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 14s 49ms/step - loss: 1.1725 - mae: 1.1725 - val_loss: 0.9692 - val_mae: 0.9692\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 14s 50ms/step - loss: 1.1798 - mae: 1.1798 - val_loss: 0.8629 - val_mae: 0.8629\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 20s 71ms/step - loss: 1.1610 - mae: 1.1610 - val_loss: 0.9258 - val_mae: 0.9258\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 17s 59ms/step - loss: 1.1432 - mae: 1.1432 - val_loss: 0.7930 - val_mae: 0.7930\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 20s 71ms/step - loss: 1.1379 - mae: 1.1379 - val_loss: 0.7559 - val_mae: 0.7559\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 16s 56ms/step - loss: 1.1272 - mae: 1.1272 - val_loss: 0.8990 - val_mae: 0.8990\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 15s 51ms/step - loss: 1.1025 - mae: 1.1025 - val_loss: 0.7602 - val_mae: 0.7602\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 14s 51ms/step - loss: 1.1243 - mae: 1.1243 - val_loss: 0.7764 - val_mae: 0.7764\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 19s 66ms/step - loss: 1.1128 - mae: 1.1128 - val_loss: 0.7700 - val_mae: 0.7700\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 19s 66ms/step - loss: 1.1258 - mae: 1.1258 - val_loss: 0.8941 - val_mae: 0.8941\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 21s 72ms/step - loss: 1.1005 - mae: 1.1005 - val_loss: 0.7419 - val_mae: 0.7419\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 17s 60ms/step - loss: 1.1237 - mae: 1.1237 - val_loss: 0.8861 - val_mae: 0.8861\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 17s 60ms/step - loss: 1.0822 - mae: 1.0822 - val_loss: 0.7554 - val_mae: 0.7554\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 15s 54ms/step - loss: 1.0951 - mae: 1.0951 - val_loss: 0.7299 - val_mae: 0.7299\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 14s 50ms/step - loss: 1.0669 - mae: 1.0669 - val_loss: 0.7844 - val_mae: 0.7844\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 16s 56ms/step - loss: 1.0837 - mae: 1.0837 - val_loss: 0.8075 - val_mae: 0.8075\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 16s 54ms/step - loss: 1.0740 - mae: 1.0740 - val_loss: 0.7732 - val_mae: 0.7732\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 15s 52ms/step - loss: 1.0790 - mae: 1.0790 - val_loss: 0.7411 - val_mae: 0.7411\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 15s 54ms/step - loss: 1.0991 - mae: 1.0991 - val_loss: 0.7718 - val_mae: 0.7718\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 15s 52ms/step - loss: 1.0706 - mae: 1.0706 - val_loss: 0.7330 - val_mae: 0.7330\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 17s 60ms/step - loss: 1.0636 - mae: 1.0636 - val_loss: 0.8299 - val_mae: 0.8299\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 12s 43ms/step - loss: 1.0627 - mae: 1.0627 - val_loss: 0.8040 - val_mae: 0.8040\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 14s 48ms/step - loss: 1.0757 - mae: 1.0757 - val_loss: 0.8014 - val_mae: 0.8014\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 13s 45ms/step - loss: 1.0631 - mae: 1.0631 - val_loss: 0.8164 - val_mae: 0.8164\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 109s 382ms/step - loss: 1.0566 - mae: 1.0566 - val_loss: 0.8448 - val_mae: 0.8448\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 118s 411ms/step - loss: 1.0535 - mae: 1.0535 - val_loss: 0.8667 - val_mae: 0.8667\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 16s 56ms/step - loss: 1.0581 - mae: 1.0581 - val_loss: 0.7350 - val_mae: 0.7350\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 120s 420ms/step - loss: 1.0415 - mae: 1.0415 - val_loss: 0.7755 - val_mae: 0.7755\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 126s 439ms/step - loss: 1.0673 - mae: 1.0673 - val_loss: 0.8432 - val_mae: 0.8432\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 24s 83ms/step - loss: 1.0481 - mae: 1.0481 - val_loss: 0.7803 - val_mae: 0.7803\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 13s 45ms/step - loss: 1.0507 - mae: 1.0507 - val_loss: 0.8542 - val_mae: 0.8542\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 14s 47ms/step - loss: 1.0606 - mae: 1.0606 - val_loss: 0.8726 - val_mae: 0.8726\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 104s 364ms/step - loss: 1.0346 - mae: 1.0346 - val_loss: 0.8057 - val_mae: 0.8057\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 106s 369ms/step - loss: 1.0398 - mae: 1.0398 - val_loss: 0.7394 - val_mae: 0.7394\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 103s 361ms/step - loss: 1.0439 - mae: 1.0439 - val_loss: 0.7838 - val_mae: 0.7838\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 12s 40ms/step - loss: 1.0484 - mae: 1.0484 - val_loss: 0.8727 - val_mae: 0.8727\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 101s 353ms/step - loss: 1.0435 - mae: 1.0435 - val_loss: 0.8246 - val_mae: 0.8246\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 93s 324ms/step - loss: 1.0169 - mae: 1.0169 - val_loss: 0.7612 - val_mae: 0.7612\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 97s 340ms/step - loss: 1.0294 - mae: 1.0294 - val_loss: 0.7516 - val_mae: 0.7516\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 113s 397ms/step - loss: 1.0501 - mae: 1.0501 - val_loss: 0.8046 - val_mae: 0.8046\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 96s 337ms/step - loss: 1.0407 - mae: 1.0407 - val_loss: 0.8329 - val_mae: 0.8329\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 1.0412 - mae: 1.0412 - val_loss: 0.7586 - val_mae: 0.7586\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 271s 949ms/step - loss: 1.0348 - mae: 1.0348 - val_loss: 0.9162 - val_mae: 0.9162\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 259s 888ms/step - loss: 1.0282 - mae: 1.0282 - val_loss: 0.7204 - val_mae: 0.7204\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 89s 311ms/step - loss: 1.0471 - mae: 1.0471 - val_loss: 0.6987 - val_mae: 0.6987\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 89s 313ms/step - loss: 1.0374 - mae: 1.0374 - val_loss: 0.8447 - val_mae: 0.8447\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 90s 316ms/step - loss: 1.0381 - mae: 1.0381 - val_loss: 0.8078 - val_mae: 0.8078\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 94s 330ms/step - loss: 1.0370 - mae: 1.0370 - val_loss: 0.8946 - val_mae: 0.8946\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 96s 337ms/step - loss: 1.0363 - mae: 1.0363 - val_loss: 0.8186 - val_mae: 0.8186\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 121s 425ms/step - loss: 1.0299 - mae: 1.0299 - val_loss: 0.7390 - val_mae: 0.7390\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 96s 334ms/step - loss: 1.0254 - mae: 1.0254 - val_loss: 0.7202 - val_mae: 0.7202\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 113s 396ms/step - loss: 1.0158 - mae: 1.0158 - val_loss: 0.9046 - val_mae: 0.9046\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 91s 317ms/step - loss: 1.0344 - mae: 1.0344 - val_loss: 0.7872 - val_mae: 0.7872\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 97s 339ms/step - loss: 1.0254 - mae: 1.0254 - val_loss: 0.7089 - val_mae: 0.7089\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 97s 339ms/step - loss: 1.0067 - mae: 1.0067 - val_loss: 0.7240 - val_mae: 0.7240\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 95s 332ms/step - loss: 1.0167 - mae: 1.0167 - val_loss: 0.7590 - val_mae: 0.7590\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 1.0158 - mae: 1.0158 - val_loss: 0.8718 - val_mae: 0.8718\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 13s 45ms/step - loss: 1.0092 - mae: 1.0092 - val_loss: 0.8337 - val_mae: 0.8337\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 125s 436ms/step - loss: 1.0150 - mae: 1.0150 - val_loss: 0.8050 - val_mae: 0.8050\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 12s 41ms/step - loss: 1.0348 - mae: 1.0348 - val_loss: 0.7642 - val_mae: 0.7642\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 94s 330ms/step - loss: 1.0214 - mae: 1.0214 - val_loss: 0.7810 - val_mae: 0.7810\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 90s 317ms/step - loss: 1.0107 - mae: 1.0107 - val_loss: 0.7487 - val_mae: 0.7487\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 91s 318ms/step - loss: 1.0173 - mae: 1.0173 - val_loss: 0.7108 - val_mae: 0.7108\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 99s 345ms/step - loss: 1.0231 - mae: 1.0231 - val_loss: 0.8274 - val_mae: 0.8274\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 109s 380ms/step - loss: 0.9980 - mae: 0.9980 - val_loss: 0.7541 - val_mae: 0.7541\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 11s 39ms/step - loss: 1.0261 - mae: 1.0261 - val_loss: 0.8855 - val_mae: 0.8855\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 106s 370ms/step - loss: 1.0207 - mae: 1.0207 - val_loss: 0.7639 - val_mae: 0.7639\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 119s 415ms/step - loss: 1.0274 - mae: 1.0274 - val_loss: 0.7573 - val_mae: 0.7573\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 153s 534ms/step - loss: 1.0166 - mae: 1.0166 - val_loss: 0.8121 - val_mae: 0.8121\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 156s 544ms/step - loss: 1.0237 - mae: 1.0237 - val_loss: 0.8590 - val_mae: 0.8590\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 147s 511ms/step - loss: 1.0175 - mae: 1.0175 - val_loss: 0.9102 - val_mae: 0.9102\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 149s 518ms/step - loss: 1.0108 - mae: 1.0108 - val_loss: 0.7408 - val_mae: 0.7408\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 124s 435ms/step - loss: 1.0086 - mae: 1.0086 - val_loss: 0.7711 - val_mae: 0.7711\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 142s 495ms/step - loss: 1.0011 - mae: 1.0011 - val_loss: 0.8210 - val_mae: 0.8210\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 169s 588ms/step - loss: 0.9970 - mae: 0.9970 - val_loss: 0.7466 - val_mae: 0.7466\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 153s 535ms/step - loss: 1.0013 - mae: 1.0013 - val_loss: 0.7377 - val_mae: 0.7377\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 192s 673ms/step - loss: 0.9840 - mae: 0.9840 - val_loss: 0.7810 - val_mae: 0.7810\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 180s 625ms/step - loss: 1.0196 - mae: 1.0196 - val_loss: 0.7845 - val_mae: 0.7845\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 226s 789ms/step - loss: 0.9986 - mae: 0.9986 - val_loss: 0.8028 - val_mae: 0.8028\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 141s 491ms/step - loss: 1.0113 - mae: 1.0113 - val_loss: 0.8168 - val_mae: 0.8168\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 180s 627ms/step - loss: 1.0043 - mae: 1.0043 - val_loss: 0.8058 - val_mae: 0.8058\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 141s 495ms/step - loss: 1.0193 - mae: 1.0193 - val_loss: 0.8151 - val_mae: 0.8151\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 333s 1s/step - loss: 1.0112 - mae: 1.0112 - val_loss: 0.7579 - val_mae: 0.7579\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 286s 985ms/step - loss: 1.0041 - mae: 1.0041 - val_loss: 0.7112 - val_mae: 0.7112\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 411s 1s/step - loss: 0.9923 - mae: 0.9923 - val_loss: 0.8156 - val_mae: 0.8156\n",
      "Epoch 90/100\n",
      "219/286 [=====================>........] - ETA: 1:27 - loss: 0.9978 - mae: 0.9978"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=100, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(val_dataset, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_not_trained/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_not_trained/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0507a03bb0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "save_path = \"saved/tf_model\"\n",
    "# tf.saved_model.save(model, save_path)\n",
    "\n",
    "run_model = tf.function(lambda x: model(x))\n",
    "BATCH_SIZE = 1\n",
    "FREQS = 201\n",
    "TIME_STEPS = 498\n",
    "concrete_func = run_model.get_concrete_function(\n",
    "    tf.TensorSpec([BATCH_SIZE, FREQS, TIME_STEPS], model.inputs[0].dtype))\n",
    "model.save(save_path, save_format=\"tf\", signatures=concrete_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tinify model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated count of arithmetic ops: 20.144 M  ops, equivalently 10.072 M  MACs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "97056"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(save_path)\n",
    "\n",
    "save_path_tflite = os.path.basename(save_path) + \".tflite\"\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "tflite_model_file = pathlib.Path(save_path_tflite)\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76a523b229c1bdfefc2e48939a50f2e7755309cd9defdafaa93eeee6ec8eda56"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('yolo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
