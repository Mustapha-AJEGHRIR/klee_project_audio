{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets transform the trained model into ONNX format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this to convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U tf2onnx\n",
    "!python -m tf2onnx.convert --saved-model ./saved/tf_model/ --output ./onnx/f-crnn.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets now test the converted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations : [-1.03178     0.37886485]\n",
      "Duration :0.001s\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "tf_random_tensor = np.random.rand(1, 201, 498)\n",
    "tf_random_tensor = tf_random_tensor.astype(np.float32)\n",
    "\n",
    "ort_sess = ort.InferenceSession('onnx/f-crnn.onnx')\n",
    "outputs = ort_sess.run([], {'x': tf_random_tensor})\n",
    "# Print Result\n",
    "# result = outputs[0].argmax(axis=1)\n",
    "print(\"Activations :\", outputs[0][0])\n",
    "# print(\"label :\",result[0])\n",
    "\n",
    "tik = time()\n",
    "ort_sess.run([], {'x': tf_random_tensor})\n",
    "tok = time()\n",
    "print(\"Duration :{:.3f}s\".format(tok-tik))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets test real inputs now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_fe1759.json\n",
      "5_fe1759.wav\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/LibriCount |grep  5_fe1759"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"sex\": \"F\", \"activity\": [[0, 32957], [33438, 53938], [56821, 58583], [58743, 80000]], \"speaker_id\": 2961}, {\"sex\": \"F\", \"activity\": [[0, 36160], [39363, 80000]], \"speaker_id\": 4970}, {\"sex\": \"F\", \"activity\": [[0, 10054], [14699, 29594], [30395, 32156], [32957, 34719], [35199, 56981], [57301, 80000]], \"speaker_id\": 4992}, {\"sex\": \"M\", \"activity\": [[0, 44489], [47852, 76360]], \"speaker_id\": 61}, {\"sex\": \"M\", \"activity\": [[0, 28152], [30395, 31836], [31996, 80000]], \"speaker_id\": 8230}]"
     ]
    }
   ],
   "source": [
    "!cat ../data/LibriCount/5_fe1759.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this audio, there is 2 M and 3 F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 201, 498)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "FFT_N_PERSEG = 400\n",
    "FFT_N_OVERLAP = 240\n",
    "FFT_WINDOW_TYPE = \"tukey\"\n",
    "EPS = 1e-8\n",
    "\n",
    "file = \"../data/LibriCount/5_fe1759.wav\"\n",
    "\n",
    "sample_rate, clip = wavfile.read(file)\n",
    "_, _, fft = scipy.signal.spectrogram(clip,\n",
    "                                            fs = sample_rate,\n",
    "                                            nperseg = FFT_N_PERSEG,\n",
    "                                            noverlap = FFT_N_OVERLAP,\n",
    "                                            window = FFT_WINDOW_TYPE\n",
    "                                            )\n",
    "\n",
    "fft = fft / (np.linalg.norm(fft, axis=0, keepdims=True) + EPS)\n",
    "fft = fft.astype(np.float32)\n",
    "fft = fft[None, :, :] # Add the batch dimension = 1\n",
    "fft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations [M, F] : [3.2492657 2.6321983]\n",
      "Duration :0.004s\n"
     ]
    }
   ],
   "source": [
    "ort_sess = ort.InferenceSession('onnx/f-crnn.onnx')\n",
    "\n",
    "tik = time()\n",
    "outputs = ort_sess.run([], {'x': fft})\n",
    "tok = time()\n",
    "print(\"Activations [M, F] :\", outputs[0][0])\n",
    "print(\"Duration :{:.3f}s\".format(tok-tik))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we round the activation values we get 3 Males and 3 Females, (Instead of 2 M and 3 F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets now use microphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16c46821c1401faaf5ad31213b2dfd6fcbee6ba139ce43836ce7acccacfff6dc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nlp_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
