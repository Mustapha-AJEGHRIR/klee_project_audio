{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets place this notebook in the root directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.insert(0,'..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Mustapha/Documents/competitions/klee_project_audio\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = %pwd\n",
    "if path.split(os.sep)[-1] == 'best_model_conversion':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also refresh all our dependecies in run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load environment variables, if they exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env_consts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------- Torch and friends ---------------------------- #\n",
    "import torch\n",
    "import onnx\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------------- other ---------------------------------- #\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "# ---------------------------------- Custom ---------------------------------- #\n",
    "from src.load_dataset_fft_aug import get_splitter_dataloaders_fft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "salade de tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 14:51:41.985796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-10 14:51:42.022304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-10 14:51:42.022796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Hide GPU from visible devices\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils for import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCRNNPermuteForLSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Permute the input from (batch, channel, time) to (batch, time, channel)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return x.permute(0, 2, 1)\n",
    "    \n",
    "class SequentialLSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    LSTMs in Pytorch, outputs a tuple (output, (h_n, c_n)), we only need output\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=1280, hidden_size=40, num_layers=1, dropout=0):\n",
    "        super().__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch model to ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = torch.load(\"custom_models/F-CRNN_mae_49_58.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1424, 0.2618]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded(torch.rand(1, 201, 498).to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model_loaded = torch.nn.Sequential( #input size = 80000\n",
    "        torch.nn.Conv1d(201, 32, kernel_size=3),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "        \n",
    "        torch.nn.Conv1d(32, 64, kernel_size=3),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "        \n",
    "        torch.nn.Conv1d(64, 64, kernel_size=3),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(0.5),\n",
    "        \n",
    "        FCRNNPermuteForLSTM(),\n",
    "        torch.nn.LSTM(64, 40, 1, dropout=0.5),).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input : Float(1, 201, 498, strides=[100098, 498, 1], requires_grad=0, device=cuda:0),\n",
      "      %0.weight : Float(32, 201, 3, strides=[603, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %0.bias : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %3.weight : Float(64, 32, 3, strides=[96, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %3.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %6.weight : Float(64, 64, 3, strides=[192, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %6.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %118 : Float(1, 160, 64, strides=[10240, 64, 1], requires_grad=0, device=cuda:0),\n",
      "      %119 : Float(1, 160, 40, strides=[6400, 40, 1], requires_grad=0, device=cuda:0),\n",
      "      %120 : Float(1, 320, strides=[320, 1], requires_grad=0, device=cuda:0),\n",
      "      %121 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %122 : Long(1, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %11 : Float(1, 32, 496, strides=[15872, 496, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[0, 0], strides=[1]](%input, %0.weight, %0.bias) # /home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/torch/nn/modules/conv.py:297:0\n",
      "  %12 : Float(1, 32, 496, strides=[15872, 496, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%11) # /home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/torch/nn/functional.py:1299:0\n",
      "  %13 : Float(1, 32, 248, strides=[7936, 248, 1], requires_grad=1, device=cuda:0) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2], pads=[0, 0], strides=[2]](%12) # /home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/torch/nn/functional.py:653:0\n",
      "  %14 : Float(1, 64, 246, strides=[15744, 246, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[0, 0], strides=[1]](%13, %3.weight, %3.bias) # /home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/torch/nn/modules/conv.py:297:0\n",
      "  %15 : Float(1, 64, 246, strides=[15744, 246, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%14) # /home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/torch/nn/functional.py:1299:0\n",
      "  %16 : Float(1, 64, 123, strides=[7872, 123, 1], requires_grad=1, device=cuda:0) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2], pads=[0, 0], strides=[2]](%15) # /home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/torch/nn/functional.py:653:0\n",
      "  %17 : Float(1, 64, 121, strides=[7744, 121, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[0, 0], strides=[1]](%16, %6.weight, %6.bias) # /home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/torch/nn/modules/conv.py:297:0\n",
      "  %18 : Float(1, 64, 121, strides=[7744, 121, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%17) # /home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/torch/nn/functional.py:1169:0\n",
      "  %19 : Float(1, 121, 64, strides=[7744, 1, 121], requires_grad=1, device=cuda:0) = onnx::Transpose[perm=[0, 2, 1]](%18) # /tmp/ipykernel_18213/3856527403.py:8:0\n",
      "  %20 : Float(1, 121, 40, strides=[4840, 40, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>]() # /home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/torch/nn/modules/rnn.py:677:0\n",
      "  %21 : Float(1, 121, 40, strides=[4840, 40, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>]() # /home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/torch/nn/modules/rnn.py:680:0\n",
      "  %22 : Tensor? = prim::Constant()\n",
      "  %79 : Long(3, strides=[1], device=cpu) = onnx::Shape(%19)\n",
      "  %80 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %81 : Long(device=cpu) = onnx::Gather(%79, %80)\n",
      "  %82 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%81)\n",
      "  %83 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={40}]()\n",
      "  %86 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%121, %82, %83)\n",
      "  %87 : Float(1, 121, 40, device=cpu) = onnx::Expand(%20, %86)\n",
      "  %88 : Long(3, strides=[1], device=cpu) = onnx::Shape(%19)\n",
      "  %89 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %90 : Long(device=cpu) = onnx::Gather(%88, %89)\n",
      "  %91 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%90)\n",
      "  %92 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={40}]()\n",
      "  %95 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%122, %91, %92)\n",
      "  %96 : Float(1, 121, 40, device=cpu) = onnx::Expand(%21, %95)\n",
      "  %97 : Float(1, 1, 121, 40, strides=[4840, 4840, 40, 1], device=cpu), %98 : Float(1, 121, 40, strides=[4840, 40, 1], requires_grad=1, device=cuda:0), %99 : Float(1, 121, 40, strides=[4840, 40, 1], requires_grad=1, device=cuda:0) = onnx::LSTM[hidden_size=40](%19, %118, %119, %120, %22, %87, %96) # /home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/torch/nn/modules/rnn.py:691:0\n",
      "  %output : Float(1, 121, 40, strides=[4840, 40, 1], requires_grad=1, device=cuda:0) = onnx::Squeeze[axes=[1]](%97) # /home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/torch/nn/modules/rnn.py:691:0\n",
      "  return (%output, %98, %99)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:2119: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\"Exporting a model to ONNX with a batch_size other than 1, \" +\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n"
     ]
    }
   ],
   "source": [
    "onnx_output_folder = \"best_model_conversion/onnx\"\n",
    "if not os.path.exists(onnx_output_folder):\n",
    "    os.makedirs(onnx_output_folder)\n",
    "torch.onnx.export(\n",
    "    model_loaded,\n",
    "    torch.randn(1, 201, 498, device=\"cuda\"),\n",
    "    os.path.join(onnx_output_folder, \"fcrnn.onnx\"),\n",
    "    opset_version=12,\n",
    "    verbose=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    # dynamic_axes={'input': {0: 'sequence'}, 'output': {0: 'sequence'}}\n",
    "    # keep_initializers_as_inputs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(os.path.join(onnx_output_folder, \"fcrnn.onnx\"))\n",
    "\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some test inference with onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 14:51:47.906341705 [W:onnxruntime:, graph.cc:1237 Graph] Initializer 0.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-03-10 14:51:47.906921146 [W:onnxruntime:, graph.cc:1237 Graph] Initializer 0.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-03-10 14:51:47.906930713 [W:onnxruntime:, graph.cc:1237 Graph] Initializer 3.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-03-10 14:51:47.906935675 [W:onnxruntime:, graph.cc:1237 Graph] Initializer 3.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-03-10 14:51:47.906939959 [W:onnxruntime:, graph.cc:1237 Graph] Initializer 6.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-03-10 14:51:47.906945371 [W:onnxruntime:, graph.cc:1237 Graph] Initializer 6.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-03-10 14:51:47.906950988 [W:onnxruntime:, graph.cc:1237 Graph] Initializer 118 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-03-10 14:51:47.906956184 [W:onnxruntime:, graph.cc:1237 Graph] Initializer 119 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-03-10 14:51:47.906961249 [W:onnxruntime:, graph.cc:1237 Graph] Initializer 120 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-03-10 14:51:47.906966547 [W:onnxruntime:, graph.cc:1237 Graph] Initializer 121 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-03-10 14:51:47.906971096 [W:onnxruntime:, graph.cc:1237 Graph] Initializer 122 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[[ 0.00070733, -0.01375907, -0.00012339, ...,  0.0065646 ,\n",
       "           0.00439894, -0.01056484],\n",
       "         [-0.006847  , -0.01803691, -0.02265233, ..., -0.01419169,\n",
       "           0.0101109 , -0.02161603],\n",
       "         [ 0.00352269, -0.037413  , -0.00238217, ...,  0.01082113,\n",
       "           0.01381979, -0.00142794],\n",
       "         ...,\n",
       "         [-0.0111691 , -0.01851932, -0.01398994, ..., -0.01366919,\n",
       "           0.00501725, -0.02036662],\n",
       "         [-0.01949888, -0.0196784 , -0.00619684, ..., -0.00768538,\n",
       "           0.00257744, -0.00301417],\n",
       "         [-0.01891368, -0.01620599, -0.00448724, ...,  0.00270507,\n",
       "           0.00804203, -0.00138754]]], dtype=float32),\n",
       " array([[[ 0.00070733, -0.01375907, -0.00012339, ...,  0.0065646 ,\n",
       "           0.00439894, -0.01056484],\n",
       "         [-0.006847  , -0.01803691, -0.02265233, ..., -0.01419169,\n",
       "           0.0101109 , -0.02161603],\n",
       "         [ 0.00352269, -0.037413  , -0.00238217, ...,  0.01082113,\n",
       "           0.01381979, -0.00142794],\n",
       "         ...,\n",
       "         [-0.0111691 , -0.01851932, -0.01398994, ..., -0.01366919,\n",
       "           0.00501725, -0.02036662],\n",
       "         [-0.01949888, -0.0196784 , -0.00619684, ..., -0.00768538,\n",
       "           0.00257744, -0.00301417],\n",
       "         [-0.01891368, -0.01620599, -0.00448724, ...,  0.00270507,\n",
       "           0.00804203, -0.00138754]]], dtype=float32),\n",
       " array([[[ 0.00131534, -0.02669715, -0.00022614, ...,  0.015258  ,\n",
       "           0.00959143, -0.02026648],\n",
       "         [-0.01320018, -0.03526177, -0.04194047, ..., -0.03312775,\n",
       "           0.02346683, -0.04060576],\n",
       "         [ 0.00676971, -0.07499336, -0.00450067, ...,  0.02548474,\n",
       "           0.03138438, -0.00269724],\n",
       "         ...,\n",
       "         [-0.02142181, -0.03681404, -0.02659202, ..., -0.03121926,\n",
       "           0.01122823, -0.03721944],\n",
       "         [-0.03696461, -0.0397999 , -0.01147596, ..., -0.01858956,\n",
       "           0.00596378, -0.00548065],\n",
       "         [-0.03593496, -0.03258451, -0.0083408 , ...,  0.00625794,\n",
       "           0.01788699, -0.00252468]]], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "ort_session = ort.InferenceSession(os.path.join(onnx_output_folder, \"fcrnn.onnx\"))\n",
    "\n",
    "outputs = ort_session.run(\n",
    "    None,\n",
    "    {'input': np.random.randn(1, 201, 498).astype(np.float32)}\n",
    ")\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNX to tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 14:51:48.593500: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:992: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  return f(*args, **kwargs)\n",
      "/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:984: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self._kernel = self.add_variable(\n",
      "/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:993: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self._bias = self.add_variable(\n",
      "/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/keras/legacy_tf_layers/base.py:573: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  _add_elements_to_collection(self.updates, tf.compat.v1.GraphKeys.UPDATE_OPS)\n",
      "2022-03-10 14:51:53.793576: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/keras/legacy_tf_layers/base.py:573: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  _add_elements_to_collection(self.updates, tf.compat.v1.GraphKeys.UPDATE_OPS)\n",
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_conversion/tf/fcrnn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_conversion/tf/fcrnn/assets\n"
     ]
    }
   ],
   "source": [
    "from onnx_tf.backend import prepare\n",
    "\n",
    "tf_output_folder = \"best_model_conversion/tf\"\n",
    "\n",
    "tf_rep = prepare(model)\n",
    "tf_rep.export_graph(os.path.join(tf_output_folder, \"fcrnn\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF to tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salade de tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# print(gpus)\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_virtual_device_configuration(\n",
    "#             gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 14:51:54.965842: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: StatefulPartitionedCall/assert_equal_1/Assert/AssertGuard/branch_executed/_24\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'LSTM_3e64b8c7/rnn/while/rnn/multi_rnn_cell/cell_0/lstm_cell/BiasAdd' defined at (most recent call last):\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_18213/3623324620.py\", line 2, in <module>\n      model = tf.saved_model.load(\"best_model_conversion/tf/fcrnn\")\nNode: 'LSTM_3e64b8c7/rnn/while/rnn/multi_rnn_cell/cell_0/lstm_cell/BiasAdd'\nMatrix size-incompatible: In[0]: [121,104], In[1]: [1,1]\n\t [[{{node LSTM_3e64b8c7/rnn/while/rnn/multi_rnn_cell/cell_0/lstm_cell/BiasAdd}}]] [Op:__inference_restored_function_body_1723]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18213/3623324620.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m201\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m498\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_call_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'LSTM_3e64b8c7/rnn/while/rnn/multi_rnn_cell/cell_0/lstm_cell/BiasAdd' defined at (most recent call last):\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/mus5900/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_18213/3623324620.py\", line 2, in <module>\n      model = tf.saved_model.load(\"best_model_conversion/tf/fcrnn\")\nNode: 'LSTM_3e64b8c7/rnn/while/rnn/multi_rnn_cell/cell_0/lstm_cell/BiasAdd'\nMatrix size-incompatible: In[0]: [121,104], In[1]: [1,1]\n\t [[{{node LSTM_3e64b8c7/rnn/while/rnn/multi_rnn_cell/cell_0/lstm_cell/BiasAdd}}]] [Op:__inference_restored_function_body_1723]"
     ]
    }
   ],
   "source": [
    "# model = tf.saved_model.load(os.path.join(tf_output_folder, \"fcrnn\"))\n",
    "model = tf.saved_model.load(\"best_model_conversion/tf/fcrnn\")\n",
    "model.trainable = False\n",
    "\n",
    "input_tensor = tf.random.uniform([1, 201, 498])\n",
    "out = model(**{'input': input_tensor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34a01c7cbd4d230e2daaa44d8acb4ab26fe27453faf910e8270bab9ecc3bb26f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('series_forcasting')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
