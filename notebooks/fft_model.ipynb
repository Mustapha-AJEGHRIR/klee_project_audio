{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets place this notebook in the root directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = %pwd\n",
    "if path.split(os.sep)[-1] == 'notebooks':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also refresh all our dependecies in run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load environment variables, if they exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env_consts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------- torch stuff ------------------------------- #\n",
    "import torch\n",
    "\n",
    "# ----------------------------------- other ---------------------------------- #\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "# ---------------------------------- Custom ---------------------------------- #\n",
    "from src.load_dataset_fft import get_splitter_dataloaders_fft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs :  {'BATCH_SIZE': 8, 'TRAIN_SPLIT': 0.8, 'FTYPE': torch.float32, 'fft_nperseg': 400, 'fft_noverlap': 240, 'fft_window_type': 'tukey', 'fft_in_db': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching dataset:  18%|█▊        | 1040/5720 [00:37<02:56, 26.56it/s]/mnt/c/Users/Mustapha/Documents/competitions/klee_project_audio/src/load_dataset_fft.py:68: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fft /= np.linalg.norm(fft, axis=0, keepdims=True)\n",
      "Caching dataset:  31%|███       | 1769/5720 [01:56<2:35:02,  2.35s/it]"
     ]
    }
   ],
   "source": [
    "F16 = torch.float16\n",
    "F32 = torch.float32\n",
    "F64 = torch.float64\n",
    "FTYPE = F32\n",
    "TRAIN_SPLIT = float(os.getenv('KLEE_TRAIN_SPLIT', 0.8))\n",
    "BATCH_SIZE = int(os.getenv('KLEE_BATCH_SIZE', 64))\n",
    "kwargs = {\n",
    "        \"BATCH_SIZE\": BATCH_SIZE,\n",
    "        \"TRAIN_SPLIT\": TRAIN_SPLIT,\n",
    "        \"FTYPE\": FTYPE,\n",
    "        \"fft_nperseg\": 400,\n",
    "        \"fft_noverlap\": 240,\n",
    "        \"fft_window_type\": \"tukey\",\n",
    "        \"fft_in_db\": False,\n",
    "        }\n",
    "print(\"kwargs : \",kwargs)\n",
    "train_loader, val_loader = get_splitter_dataloaders_fft(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 201, 498])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example, lab = train_loader.dataset[0]\n",
    "example.shape  # (channel, frequency, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"klee_project_audio\", entity=\"mustapha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original model CRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PermuteForLSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Permute the input from (batch, channel, freq, time) to (batch, time, freq, channel)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return x.permute(0, 3, 2, 1)\n",
    "    \n",
    "\n",
    "class ReshapForLSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Reshape the input from (batch, time, freq, channel) to (batch, time, freq*channel)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return x.reshape(x.shape[0], x.shape[1], -1)\n",
    "\n",
    "class SequentialLSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    LSTMs in Pytorch, outputs a tuple (output, (h_n, c_n)), we only need output\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=1280, hidden_size=40, num_layers=1, dropout=0):\n",
    "        super().__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch sequential\n",
    "class Parameters():\n",
    "    def __init__(self, parameters):\n",
    "        self.__dict__.update(parameters)\n",
    "\n",
    "def CRNN(p):\n",
    "    return torch.nn.Sequential( #input size = 80000\n",
    "        torch.nn.Conv2d(1, 64, kernel_size=3),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(64, 32, kernel_size=3),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size=3, stride=3),\n",
    "        \n",
    "        torch.nn.Conv2d(32, 128, kernel_size=3),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(128, 64, kernel_size=3),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size=3, stride=3),\n",
    "        \n",
    "        torch.nn.Dropout(p.dropout),\n",
    "        #permute 3 with 1\n",
    "        PermuteForLSTM(),\n",
    "        ReshapForLSTM(),\n",
    "        SequentialLSTM(1280, 40), # 1280 = 20 freq *64 channels\n",
    "        torch.nn.Tanh(),\n",
    "        torch.nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(53*20, 11), # Original contains 52*20, I don't know why !\n",
    "        torch.nn.Softmax(dim=1)\n",
    "    )\n",
    "\n",
    "params = Parameters({\n",
    "    \"dropout\": 0.5,\n",
    "})\n",
    "model = CRNN(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(example.unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-2\n",
    "EPOCHS = 700\n",
    "MODEL_DROPOUT = params.dropout\n",
    "EVAL_EACH = 10\n",
    "\n",
    "wandb.config.update({\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"MODEL_DROPOUT\": MODEL_DROPOUT,\n",
    "    \"OPTIMIZER\": \"ADAM\",\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "model.to(\"cuda\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # -------------------------------- Train loop -------------------------------- #\n",
    "    train_mean_loss = 0\n",
    "    train_mean_count_loss = 0\n",
    "    for d in tqdm(train_loader, \"training loop\"):\n",
    "        audios = d[0].to(\"cuda\")\n",
    "        labels = d[1]\n",
    "        # one hot encode labels\n",
    "        count_labels = labels.sum(axis=1)\n",
    "        one_hot_label = torch.eye(11)[count_labels].to(\"cuda\")\n",
    "        # forward pass\n",
    "        predictions = model.forward(audios)\n",
    "        # count loss\n",
    "        count_loss_value = loss(predictions, one_hot_label)\n",
    "        train_mean_count_loss += count_loss_value.item()\n",
    "        #optimize\n",
    "        optimizer.zero_grad()\n",
    "        count_loss_value.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch {}/{}\".format(epoch+1, EPOCHS))\n",
    "    print(\"Train count Loss : {:.4f}\".format(train_mean_count_loss/len(train_loader)))\n",
    "    log = {\n",
    "        \"count_loss\":train_mean_count_loss/len(train_loader),\n",
    "        \"epoch\":epoch\n",
    "        }\n",
    "    # --------------------------------- Eval loop -------------------------------- #\n",
    "    if (epoch+1)%EVAL_EACH == 0:\n",
    "        val_mean_loss = 0\n",
    "        val_mean_count_loss = 0\n",
    "        model.eval()\n",
    "        for d in tqdm(val_loader, \"evaluation loop\"):\n",
    "            audios = d[0].to(\"cuda\")\n",
    "            labels = d[1]\n",
    "            # one hot encode labels\n",
    "            count_labels = labels.sum(axis=1)\n",
    "            one_hot_label = torch.eye(11)[count_labels].to(\"cuda\")\n",
    "            # forward pass\n",
    "            predictions = model.forward(audios)\n",
    "            # count loss\n",
    "            count_loss_value = loss(predictions, one_hot_label)\n",
    "            val_mean_count_loss += count_loss_value.item()\n",
    "        model.train()\n",
    "        log[\"val_count_loss\"] = val_mean_count_loss/len(val_loader)\n",
    "        print(\"validation count Loss : {:.4f}\".format(val_mean_count_loss/len(val_loader)))\n",
    "        \n",
    "    wandb.log(log)\n",
    "    # wandb.watch(model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34a01c7cbd4d230e2daaa44d8acb4ab26fe27453faf910e8270bab9ecc3bb26f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('series_forcasting')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
