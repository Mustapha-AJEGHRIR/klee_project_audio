{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets place this notebook in the root directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/projects/klee_project_audio\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = %pwd\n",
    "if path.split(os.sep)[-1] == 'notebooks':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also refresh all our dependecies in run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load environment variables, if they exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env_consts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------- torch stuff ------------------------------- #\n",
    "import torch\n",
    "\n",
    "# ----------------------------------- other ---------------------------------- #\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "# ---------------------------------- Custom ---------------------------------- #\n",
    "from src.load_dataset_fft import get_splitter_dataloaders_fft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs :  {'BATCH_SIZE': 64, 'TRAIN_SPLIT': 0.8, 'FTYPE': torch.float32, 'fft_nperseg': 400, 'fft_noverlap': 240, 'fft_window_type': 'tukey', 'fft_in_db': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching dataset:  23%|██▎       | 1313/5720 [00:04<00:14, 297.14it/s]/home/studio-lab-user/sagemaker-studiolab-notebooks/projects/klee_project_audio/src/load_dataset_fft.py:69: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fft /= np.linalg.norm(fft, axis=0, keepdims=True)\n",
      "Caching dataset: 100%|██████████| 5720/5720 [00:19<00:00, 294.13it/s]\n"
     ]
    }
   ],
   "source": [
    "F16 = torch.float16\n",
    "F32 = torch.float32\n",
    "F64 = torch.float64\n",
    "FTYPE = F32\n",
    "TRAIN_SPLIT = float(os.getenv('KLEE_TRAIN_SPLIT', 0.8))\n",
    "BATCH_SIZE = int(os.getenv('KLEE_BATCH_SIZE', 64))\n",
    "kwargs = {\n",
    "        \"BATCH_SIZE\": BATCH_SIZE,\n",
    "        \"TRAIN_SPLIT\": TRAIN_SPLIT,\n",
    "        \"FTYPE\": FTYPE,\n",
    "        \"fft_nperseg\": 400,\n",
    "        \"fft_noverlap\": 240,\n",
    "        \"fft_window_type\": \"tukey\",\n",
    "        \"fft_in_db\": True,\n",
    "        }\n",
    "print(\"kwargs : \",kwargs)\n",
    "train_loader, val_loader = get_splitter_dataloaders_fft(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 201, 498])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example, lab = train_loader.dataset[0]\n",
    "example.shape  # (channel, frequency, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmustapha\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/mustapha/klee_project_audio/runs/28xudanl\" target=\"_blank\">twilight-gorge-39</a></strong> to <a href=\"https://wandb.ai/mustapha/klee_project_audio\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/mustapha/klee_project_audio/runs/28xudanl?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fa3a01fad00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"klee_project_audio\", entity=\"mustapha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original model CRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PermuteForLSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Permute the input from (batch, channel, freq, time) to (batch, time, freq, channel)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return x.permute(0, 3, 2, 1)\n",
    "    \n",
    "\n",
    "class ReshapForLSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Reshape the input from (batch, time, freq, channel) to (batch, time, freq*channel)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return x.reshape(x.shape[0], x.shape[1], -1)\n",
    "\n",
    "class SequentialLSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    LSTMs in Pytorch, outputs a tuple (output, (h_n, c_n)), we only need output\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=1280, hidden_size=40, num_layers=1, dropout=0):\n",
    "        super().__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch sequential\n",
    "class Parameters():\n",
    "    def __init__(self, parameters):\n",
    "        self.__dict__.update(parameters)\n",
    "\n",
    "def CRNN(p):\n",
    "    return torch.nn.Sequential( #input size = 80000\n",
    "        torch.nn.Conv2d(1, 64, kernel_size=3),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(64, 32, kernel_size=3),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size=3, stride=3),\n",
    "        \n",
    "        torch.nn.Conv2d(32, 128, kernel_size=3),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(128, 64, kernel_size=3),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size=3, stride=3),\n",
    "        \n",
    "        torch.nn.Dropout(p.dropout),\n",
    "        #permute 3 with 1\n",
    "        PermuteForLSTM(),\n",
    "        ReshapForLSTM(),\n",
    "        SequentialLSTM(1280, 40), # 1280 = 20 freq *64 channels\n",
    "        torch.nn.Tanh(),\n",
    "        torch.nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(53*20, 11), # Original contains 52*20, I don't know why !\n",
    "        torch.nn.Softmax(dim=1)\n",
    "    )\n",
    "\n",
    "params = Parameters({\n",
    "    \"dropout\": 0.2,\n",
    "})\n",
    "model = CRNN(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(example.unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 700\n",
    "MODEL_DROPOUT = params.dropout\n",
    "EVAL_EACH = 10\n",
    "\n",
    "wandb.config.update({\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"MODEL\" : \"RCNN\",\n",
    "    \"MODEL_DROPOUT\": MODEL_DROPOUT,\n",
    "    \"OPTIMIZER\": \"ADAM\",\n",
    "    # \"batch_size\": BATCH_SIZE,\n",
    "    **kwargs\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._resume_backend at 0x7fa3a0a2d310> (for pre_run_cell):\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_resume_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jupyter_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface_queue.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   1%|▏         | 1/72 [00:00<00:29,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels : torch.Size([64, 11])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predictions : torch.Size([64, 11])\n",
      "tensor([[2.2024e-08, 6.6646e-08, 9.9998e-01, 1.5364e-08, 2.1594e-07, 8.0634e-07,\n",
      "         1.5874e-07, 5.6380e-06, 3.0420e-06, 6.8501e-06, 2.1479e-09],\n",
      "        [4.3117e-10, 1.7210e-09, 1.0000e+00, 3.0146e-10, 6.6302e-09, 3.4372e-08,\n",
      "         5.2546e-09, 4.2759e-07, 1.6471e-07, 5.4905e-07, 2.2405e-11],\n",
      "        [1.5473e-10, 6.5418e-10, 1.0000e+00, 1.1426e-10, 2.9176e-09, 1.5959e-08,\n",
      "         2.1819e-09, 2.2313e-07, 8.8107e-08, 2.9306e-07, 7.1327e-12],\n",
      "        [1.2601e-10, 5.3375e-10, 1.0000e+00, 9.4789e-11, 2.5185e-09, 1.3306e-08,\n",
      "         1.8077e-09, 2.0877e-07, 7.4559e-08, 2.6315e-07, 5.6111e-12],\n",
      "        [1.0430e-10, 4.4324e-10, 1.0000e+00, 7.7088e-11, 2.0450e-09, 1.1462e-08,\n",
      "         1.5675e-09, 1.8230e-07, 6.1679e-08, 2.3513e-07, 4.3084e-12],\n",
      "        [1.1171e-10, 4.8241e-10, 1.0000e+00, 7.9085e-11, 2.1798e-09, 1.2259e-08,\n",
      "         1.5830e-09, 1.8477e-07, 6.5068e-08, 2.3066e-07, 4.8519e-12],\n",
      "        [1.0522e-10, 4.6171e-10, 1.0000e+00, 7.9262e-11, 2.0598e-09, 1.1673e-08,\n",
      "         1.6363e-09, 1.7632e-07, 6.2180e-08, 2.3299e-07, 4.7770e-12],\n",
      "        [1.1611e-10, 5.1015e-10, 1.0000e+00, 8.5195e-11, 2.3428e-09, 1.2910e-08,\n",
      "         1.6830e-09, 1.8977e-07, 6.8479e-08, 2.4523e-07, 5.2030e-12],\n",
      "        [9.6993e-11, 4.0820e-10, 1.0000e+00, 6.8231e-11, 1.9142e-09, 1.0916e-08,\n",
      "         1.4142e-09, 1.6515e-07, 5.6139e-08, 2.0989e-07, 4.2451e-12],\n",
      "        [1.1596e-10, 4.8486e-10, 1.0000e+00, 8.6053e-11, 2.3159e-09, 1.2875e-08,\n",
      "         1.6842e-09, 1.9245e-07, 6.8050e-08, 2.4749e-07, 5.0884e-12],\n",
      "        [9.7235e-11, 4.2875e-10, 1.0000e+00, 7.3246e-11, 1.8905e-09, 1.1180e-08,\n",
      "         1.4362e-09, 1.6463e-07, 6.0720e-08, 2.1452e-07, 4.2375e-12],\n",
      "        [1.1376e-10, 4.8215e-10, 1.0000e+00, 8.2070e-11, 2.1602e-09, 1.2395e-08,\n",
      "         1.6578e-09, 1.9167e-07, 6.6048e-08, 2.3660e-07, 4.8783e-12],\n",
      "        [1.0414e-10, 4.4197e-10, 1.0000e+00, 7.4030e-11, 2.0591e-09, 1.1459e-08,\n",
      "         1.5785e-09, 1.7847e-07, 6.4856e-08, 2.2539e-07, 4.6019e-12],\n",
      "        [9.5546e-11, 4.1396e-10, 1.0000e+00, 7.0087e-11, 1.9129e-09, 1.0494e-08,\n",
      "         1.4264e-09, 1.7250e-07, 6.0763e-08, 2.1354e-07, 4.1789e-12],\n",
      "        [1.2190e-10, 5.2138e-10, 1.0000e+00, 9.4242e-11, 2.4264e-09, 1.3448e-08,\n",
      "         1.7865e-09, 2.0179e-07, 7.2621e-08, 2.5393e-07, 5.6599e-12],\n",
      "        [8.1054e-11, 3.5634e-10, 1.0000e+00, 6.1773e-11, 1.6697e-09, 9.4722e-09,\n",
      "         1.2340e-09, 1.4797e-07, 5.0645e-08, 1.8626e-07, 3.6160e-12],\n",
      "        [8.1988e-11, 3.6477e-10, 1.0000e+00, 6.2743e-11, 1.6939e-09, 9.7699e-09,\n",
      "         1.2938e-09, 1.5152e-07, 5.1031e-08, 1.9386e-07, 3.6264e-12],\n",
      "        [1.0065e-10, 4.1225e-10, 1.0000e+00, 7.1137e-11, 1.9283e-09, 1.1241e-08,\n",
      "         1.4808e-09, 1.7249e-07, 5.9320e-08, 2.1368e-07, 4.4466e-12],\n",
      "        [9.2730e-11, 3.8932e-10, 1.0000e+00, 6.7320e-11, 1.8581e-09, 1.0402e-08,\n",
      "         1.3357e-09, 1.6195e-07, 5.6745e-08, 2.1201e-07, 3.7895e-12],\n",
      "        [8.8049e-11, 3.8061e-10, 1.0000e+00, 6.4046e-11, 1.7937e-09, 9.8070e-09,\n",
      "         1.3041e-09, 1.5318e-07, 5.3931e-08, 1.8931e-07, 3.6927e-12],\n",
      "        [7.9275e-11, 3.4630e-10, 1.0000e+00, 5.6938e-11, 1.5391e-09, 8.8175e-09,\n",
      "         1.1888e-09, 1.3985e-07, 5.1173e-08, 1.8440e-07, 3.2953e-12],\n",
      "        [8.6855e-11, 3.8779e-10, 1.0000e+00, 6.3934e-11, 1.7450e-09, 1.0101e-08,\n",
      "         1.3492e-09, 1.5727e-07, 5.4851e-08, 2.0069e-07, 3.7978e-12],\n",
      "        [9.2935e-11, 4.0701e-10, 1.0000e+00, 6.8003e-11, 1.8600e-09, 1.0624e-08,\n",
      "         1.4386e-09, 1.6244e-07, 5.7851e-08, 2.0830e-07, 4.0066e-12],\n",
      "        [1.0113e-10, 4.2988e-10, 1.0000e+00, 7.3464e-11, 1.9772e-09, 1.0952e-08,\n",
      "         1.4520e-09, 1.6984e-07, 6.1213e-08, 2.1126e-07, 4.4322e-12],\n",
      "        [7.9609e-11, 3.5632e-10, 1.0000e+00, 5.8979e-11, 1.6194e-09, 9.2933e-09,\n",
      "         1.2856e-09, 1.4717e-07, 5.1824e-08, 1.8941e-07, 3.4254e-12],\n",
      "        [9.2087e-11, 3.9341e-10, 1.0000e+00, 6.7596e-11, 1.8426e-09, 1.0120e-08,\n",
      "         1.3974e-09, 1.5774e-07, 5.4180e-08, 2.0228e-07, 3.8353e-12],\n",
      "        [1.0423e-10, 4.5413e-10, 1.0000e+00, 7.6798e-11, 2.0437e-09, 1.1236e-08,\n",
      "         1.5338e-09, 1.7348e-07, 6.3264e-08, 2.2371e-07, 4.6534e-12],\n",
      "        [9.7911e-11, 4.1163e-10, 1.0000e+00, 7.0911e-11, 1.8616e-09, 1.0763e-08,\n",
      "         1.4317e-09, 1.7407e-07, 5.9099e-08, 2.0655e-07, 4.0215e-12],\n",
      "        [9.5322e-11, 4.1288e-10, 1.0000e+00, 6.8389e-11, 1.8715e-09, 1.0763e-08,\n",
      "         1.4084e-09, 1.6186e-07, 5.6594e-08, 2.0862e-07, 4.0781e-12],\n",
      "        [1.0668e-10, 4.4828e-10, 1.0000e+00, 7.8449e-11, 2.0618e-09, 1.1039e-08,\n",
      "         1.4964e-09, 1.7067e-07, 5.9780e-08, 2.2303e-07, 4.4266e-12],\n",
      "        [1.0845e-10, 4.5995e-10, 1.0000e+00, 7.8950e-11, 2.1239e-09, 1.1672e-08,\n",
      "         1.6427e-09, 1.8616e-07, 6.3621e-08, 2.2504e-07, 4.7649e-12],\n",
      "        [9.6557e-11, 4.0087e-10, 1.0000e+00, 7.1855e-11, 1.9105e-09, 1.0430e-08,\n",
      "         1.4561e-09, 1.6411e-07, 5.8893e-08, 2.1204e-07, 4.1895e-12],\n",
      "        [1.0167e-10, 4.2622e-10, 1.0000e+00, 7.3720e-11, 1.9262e-09, 1.0608e-08,\n",
      "         1.4934e-09, 1.6265e-07, 5.6464e-08, 2.2130e-07, 4.2883e-12],\n",
      "        [1.0073e-10, 4.3110e-10, 1.0000e+00, 7.1892e-11, 1.9839e-09, 1.0743e-08,\n",
      "         1.5108e-09, 1.6783e-07, 5.9679e-08, 2.2411e-07, 4.2463e-12],\n",
      "        [1.0897e-10, 4.7186e-10, 1.0000e+00, 7.9488e-11, 2.0672e-09, 1.1619e-08,\n",
      "         1.6117e-09, 1.7623e-07, 6.3592e-08, 2.2851e-07, 4.6920e-12],\n",
      "        [1.1477e-10, 4.7929e-10, 1.0000e+00, 8.0236e-11, 2.2510e-09, 1.1873e-08,\n",
      "         1.5889e-09, 1.7805e-07, 6.4404e-08, 2.4328e-07, 4.8918e-12],\n",
      "        [1.2391e-10, 5.1844e-10, 1.0000e+00, 9.3148e-11, 2.3406e-09, 1.3099e-08,\n",
      "         1.7775e-09, 2.0920e-07, 7.2755e-08, 2.5956e-07, 5.3312e-12],\n",
      "        [9.3325e-11, 4.1182e-10, 1.0000e+00, 6.9843e-11, 1.8820e-09, 1.0558e-08,\n",
      "         1.4245e-09, 1.6147e-07, 5.6286e-08, 2.1068e-07, 3.9549e-12],\n",
      "        [1.1240e-10, 4.7353e-10, 1.0000e+00, 8.1545e-11, 2.2298e-09, 1.2188e-08,\n",
      "         1.6826e-09, 1.8685e-07, 6.7951e-08, 2.3842e-07, 4.9178e-12],\n",
      "        [7.9915e-11, 3.4408e-10, 1.0000e+00, 5.7365e-11, 1.5747e-09, 9.2940e-09,\n",
      "         1.2098e-09, 1.4809e-07, 5.1364e-08, 1.8740e-07, 3.3143e-12],\n",
      "        [9.7299e-11, 4.3157e-10, 1.0000e+00, 7.2138e-11, 1.9666e-09, 1.1222e-08,\n",
      "         1.4752e-09, 1.6708e-07, 5.7981e-08, 2.1888e-07, 4.1683e-12],\n",
      "        [1.0609e-10, 4.5691e-10, 1.0000e+00, 7.6153e-11, 2.0557e-09, 1.1305e-08,\n",
      "         1.5306e-09, 1.7639e-07, 6.0738e-08, 2.2576e-07, 4.6902e-12],\n",
      "        [1.0321e-10, 4.3652e-10, 1.0000e+00, 7.7002e-11, 2.0695e-09, 1.1733e-08,\n",
      "         1.4950e-09, 1.7327e-07, 5.9423e-08, 2.2149e-07, 4.4056e-12],\n",
      "        [1.0582e-10, 4.4933e-10, 1.0000e+00, 7.6314e-11, 2.1130e-09, 1.1457e-08,\n",
      "         1.5945e-09, 1.7716e-07, 6.2692e-08, 2.3606e-07, 4.4917e-12],\n",
      "        [9.6912e-11, 4.0605e-10, 1.0000e+00, 6.8864e-11, 1.9226e-09, 1.0993e-08,\n",
      "         1.3971e-09, 1.6713e-07, 5.8446e-08, 2.1597e-07, 4.0261e-12],\n",
      "        [9.1020e-11, 3.8491e-10, 1.0000e+00, 6.8696e-11, 1.8391e-09, 1.0698e-08,\n",
      "         1.3566e-09, 1.6685e-07, 5.7476e-08, 2.1525e-07, 3.9548e-12],\n",
      "        [7.9841e-11, 3.5556e-10, 1.0000e+00, 5.9353e-11, 1.6567e-09, 9.3862e-09,\n",
      "         1.2928e-09, 1.4758e-07, 5.1083e-08, 1.8654e-07, 3.6157e-12],\n",
      "        [7.6498e-11, 3.2993e-10, 1.0000e+00, 5.5534e-11, 1.5822e-09, 9.0974e-09,\n",
      "         1.1298e-09, 1.3839e-07, 4.9846e-08, 1.8461e-07, 3.2152e-12],\n",
      "        [7.7781e-11, 3.4248e-10, 1.0000e+00, 5.7588e-11, 1.6678e-09, 8.9261e-09,\n",
      "         1.1967e-09, 1.4291e-07, 4.9506e-08, 1.9055e-07, 3.4254e-12],\n",
      "        [9.3499e-11, 4.0829e-10, 1.0000e+00, 6.9477e-11, 1.8786e-09, 1.0343e-08,\n",
      "         1.4053e-09, 1.6068e-07, 5.6712e-08, 2.1459e-07, 4.2150e-12],\n",
      "        [9.7138e-11, 3.9984e-10, 1.0000e+00, 7.3154e-11, 1.8883e-09, 1.0718e-08,\n",
      "         1.4695e-09, 1.6942e-07, 5.8684e-08, 2.2748e-07, 4.1341e-12],\n",
      "        [9.9498e-11, 4.2401e-10, 1.0000e+00, 7.3001e-11, 1.9305e-09, 1.1042e-08,\n",
      "         1.4901e-09, 1.7048e-07, 5.8696e-08, 2.1606e-07, 4.3954e-12],\n",
      "        [1.1152e-10, 4.6828e-10, 1.0000e+00, 8.0635e-11, 2.1017e-09, 1.2156e-08,\n",
      "         1.6230e-09, 1.7268e-07, 6.0995e-08, 2.2987e-07, 4.9289e-12],\n",
      "        [9.9638e-11, 4.3705e-10, 1.0000e+00, 7.4008e-11, 1.9923e-09, 1.1056e-08,\n",
      "         1.4743e-09, 1.7325e-07, 6.0207e-08, 2.1965e-07, 4.3740e-12],\n",
      "        [1.0644e-10, 4.7050e-10, 1.0000e+00, 8.3565e-11, 2.1979e-09, 1.1869e-08,\n",
      "         1.6573e-09, 1.9101e-07, 6.3850e-08, 2.4099e-07, 4.9191e-12],\n",
      "        [1.0052e-10, 4.2843e-10, 1.0000e+00, 7.3263e-11, 1.9991e-09, 1.0623e-08,\n",
      "         1.4714e-09, 1.7536e-07, 5.8488e-08, 2.1359e-07, 4.4199e-12],\n",
      "        [1.0032e-10, 4.2550e-10, 1.0000e+00, 7.3088e-11, 2.0309e-09, 1.0857e-08,\n",
      "         1.4903e-09, 1.7052e-07, 5.9676e-08, 2.1407e-07, 4.2403e-12],\n",
      "        [8.8335e-11, 3.8780e-10, 1.0000e+00, 6.8730e-11, 1.8481e-09, 1.0274e-08,\n",
      "         1.4387e-09, 1.6036e-07, 5.9351e-08, 2.1667e-07, 3.9691e-12],\n",
      "        [1.0608e-10, 4.4210e-10, 1.0000e+00, 7.3057e-11, 2.0305e-09, 1.1256e-08,\n",
      "         1.5311e-09, 1.6814e-07, 6.1505e-08, 2.2229e-07, 4.4972e-12],\n",
      "        [8.5365e-11, 3.8024e-10, 1.0000e+00, 6.3324e-11, 1.7122e-09, 1.0096e-08,\n",
      "         1.2503e-09, 1.5116e-07, 5.2460e-08, 2.0747e-07, 3.8367e-12],\n",
      "        [9.9252e-11, 4.2733e-10, 1.0000e+00, 7.3140e-11, 1.9212e-09, 1.1043e-08,\n",
      "         1.4725e-09, 1.7055e-07, 5.6683e-08, 2.2183e-07, 4.2484e-12],\n",
      "        [1.0140e-10, 4.3490e-10, 1.0000e+00, 7.4263e-11, 1.9804e-09, 1.1096e-08,\n",
      "         1.4805e-09, 1.7051e-07, 5.9013e-08, 2.2324e-07, 4.3203e-12],\n",
      "        [1.1028e-10, 4.6149e-10, 1.0000e+00, 8.2483e-11, 2.1150e-09, 1.1961e-08,\n",
      "         1.6515e-09, 1.8978e-07, 6.4706e-08, 2.3662e-07, 4.6820e-12],\n",
      "        [9.7227e-11, 3.9950e-10, 1.0000e+00, 6.9785e-11, 1.8636e-09, 1.0740e-08,\n",
      "         1.3486e-09, 1.5901e-07, 5.6618e-08, 2.0465e-07, 4.1691e-12]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   3%|▎         | 2/72 [00:00<00:33,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels : torch.Size([64, 11])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predictions : torch.Size([64, 11])\n",
      "tensor([[3.3220e-08, 9.4103e-08, 9.9998e-01, 2.3208e-08, 3.1144e-07, 1.1605e-06,\n",
      "         2.3090e-07, 7.3020e-06, 4.1643e-06, 9.3701e-06, 3.0825e-09],\n",
      "        [4.1305e-10, 1.6437e-09, 1.0000e+00, 2.9926e-10, 7.2391e-09, 3.4763e-08,\n",
      "         5.5060e-09, 4.3234e-07, 1.8305e-07, 5.9961e-07, 2.1699e-11],\n",
      "        [1.9534e-10, 8.1585e-10, 1.0000e+00, 1.4102e-10, 3.7174e-09, 1.9450e-08,\n",
      "         2.7151e-09, 2.7469e-07, 9.9057e-08, 3.5851e-07, 9.0433e-12],\n",
      "        [1.6418e-10, 6.5456e-10, 1.0000e+00, 1.1899e-10, 3.0737e-09, 1.6615e-08,\n",
      "         2.3336e-09, 2.4802e-07, 8.8471e-08, 3.3874e-07, 7.2686e-12],\n",
      "        [1.5326e-10, 6.5576e-10, 1.0000e+00, 1.1782e-10, 2.9717e-09, 1.5816e-08,\n",
      "         2.1835e-09, 2.2835e-07, 8.6024e-08, 3.3478e-07, 6.8993e-12],\n",
      "        [1.0818e-10, 4.7710e-10, 1.0000e+00, 8.2333e-11, 2.1977e-09, 1.1823e-08,\n",
      "         1.6054e-09, 1.9440e-07, 6.8847e-08, 2.7585e-07, 4.8918e-12],\n",
      "        [1.3289e-10, 5.5630e-10, 1.0000e+00, 9.8308e-11, 2.6242e-09, 1.4402e-08,\n",
      "         1.9690e-09, 2.1116e-07, 7.7478e-08, 3.1246e-07, 5.7372e-12],\n",
      "        [1.4600e-10, 6.5380e-10, 1.0000e+00, 1.1214e-10, 2.8374e-09, 1.5650e-08,\n",
      "         2.1554e-09, 2.4209e-07, 8.6844e-08, 3.1940e-07, 6.4525e-12],\n",
      "        [1.2233e-10, 5.0465e-10, 1.0000e+00, 8.5623e-11, 2.2978e-09, 1.3394e-08,\n",
      "         1.7339e-09, 2.0360e-07, 7.0657e-08, 2.7795e-07, 5.2694e-12],\n",
      "        [1.1924e-10, 5.2268e-10, 1.0000e+00, 8.7635e-11, 2.3493e-09, 1.2853e-08,\n",
      "         1.7449e-09, 1.9454e-07, 6.8660e-08, 2.7397e-07, 5.0099e-12],\n",
      "        [1.4243e-10, 5.9646e-10, 1.0000e+00, 9.9679e-11, 2.7040e-09, 1.4527e-08,\n",
      "         1.9953e-09, 2.1607e-07, 7.9676e-08, 2.9933e-07, 6.3389e-12],\n",
      "        [1.0948e-10, 4.6132e-10, 1.0000e+00, 7.7324e-11, 2.1373e-09, 1.1658e-08,\n",
      "         1.5504e-09, 1.7988e-07, 6.3650e-08, 2.5296e-07, 4.6202e-12],\n",
      "        [1.1499e-10, 4.8476e-10, 1.0000e+00, 8.4156e-11, 2.1769e-09, 1.2393e-08,\n",
      "         1.6624e-09, 1.8085e-07, 6.8508e-08, 2.5915e-07, 4.8027e-12],\n",
      "        [1.1439e-10, 4.8052e-10, 1.0000e+00, 8.4153e-11, 2.2823e-09, 1.2214e-08,\n",
      "         1.7367e-09, 1.9222e-07, 6.9619e-08, 2.7117e-07, 4.8371e-12],\n",
      "        [1.3925e-10, 5.6321e-10, 1.0000e+00, 1.0097e-10, 2.5520e-09, 1.4441e-08,\n",
      "         1.9502e-09, 2.1385e-07, 7.8348e-08, 3.1015e-07, 6.0641e-12],\n",
      "        [1.2926e-10, 5.3250e-10, 1.0000e+00, 9.1591e-11, 2.3819e-09, 1.3505e-08,\n",
      "         1.7825e-09, 2.0125e-07, 7.3536e-08, 2.8366e-07, 5.4318e-12],\n",
      "        [1.1166e-10, 4.9069e-10, 1.0000e+00, 8.5927e-11, 2.1110e-09, 1.1779e-08,\n",
      "         1.5598e-09, 1.8223e-07, 6.4958e-08, 2.6906e-07, 5.0644e-12],\n",
      "        [1.2254e-10, 5.3685e-10, 1.0000e+00, 9.2576e-11, 2.3870e-09, 1.3202e-08,\n",
      "         1.8146e-09, 1.9787e-07, 7.2062e-08, 2.7665e-07, 5.5199e-12],\n",
      "        [1.2034e-10, 5.0946e-10, 1.0000e+00, 8.9795e-11, 2.3225e-09, 1.3203e-08,\n",
      "         1.8116e-09, 1.9626e-07, 7.1457e-08, 2.7625e-07, 5.6342e-12],\n",
      "        [1.2268e-10, 5.1767e-10, 1.0000e+00, 8.9375e-11, 2.4588e-09, 1.3065e-08,\n",
      "         1.7725e-09, 1.9899e-07, 7.3020e-08, 2.8508e-07, 5.5366e-12],\n",
      "        [1.2822e-10, 5.4693e-10, 1.0000e+00, 9.4430e-11, 2.4319e-09, 1.3381e-08,\n",
      "         1.8459e-09, 2.1590e-07, 7.6803e-08, 2.9438e-07, 5.6640e-12],\n",
      "        [1.2355e-10, 5.2344e-10, 1.0000e+00, 8.7242e-11, 2.3439e-09, 1.3614e-08,\n",
      "         1.7351e-09, 2.0196e-07, 6.8820e-08, 2.8102e-07, 5.1994e-12],\n",
      "        [1.1186e-10, 5.0266e-10, 1.0000e+00, 8.5473e-11, 2.3015e-09, 1.2773e-08,\n",
      "         1.6757e-09, 1.8455e-07, 7.1548e-08, 2.8001e-07, 5.0768e-12],\n",
      "        [1.0430e-10, 4.4472e-10, 1.0000e+00, 7.6055e-11, 2.0952e-09, 1.1808e-08,\n",
      "         1.5550e-09, 1.7689e-07, 6.3619e-08, 2.6040e-07, 4.4601e-12],\n",
      "        [1.2500e-10, 5.3336e-10, 1.0000e+00, 9.4697e-11, 2.5024e-09, 1.3661e-08,\n",
      "         1.8061e-09, 2.0767e-07, 7.3089e-08, 2.9175e-07, 5.6888e-12],\n",
      "        [1.2250e-10, 5.1634e-10, 1.0000e+00, 8.9540e-11, 2.3750e-09, 1.2985e-08,\n",
      "         1.7796e-09, 1.9619e-07, 7.1505e-08, 2.8598e-07, 5.4466e-12],\n",
      "        [1.3920e-10, 6.0281e-10, 1.0000e+00, 1.0538e-10, 2.6782e-09, 1.4529e-08,\n",
      "         2.0156e-09, 2.1225e-07, 7.7689e-08, 3.0262e-07, 6.1766e-12],\n",
      "        [1.1964e-10, 5.2044e-10, 1.0000e+00, 8.5892e-11, 2.3423e-09, 1.2962e-08,\n",
      "         1.7646e-09, 1.9979e-07, 7.1146e-08, 2.7421e-07, 5.3934e-12],\n",
      "        [1.3045e-10, 5.4314e-10, 1.0000e+00, 9.0700e-11, 2.5098e-09, 1.3212e-08,\n",
      "         1.8621e-09, 2.0603e-07, 7.1975e-08, 2.8890e-07, 5.6392e-12],\n",
      "        [1.3535e-10, 5.6988e-10, 1.0000e+00, 9.6728e-11, 2.5231e-09, 1.4355e-08,\n",
      "         1.9347e-09, 2.1608e-07, 7.8101e-08, 2.8566e-07, 5.8113e-12],\n",
      "        [1.0747e-10, 4.5717e-10, 1.0000e+00, 7.9390e-11, 2.1473e-09, 1.2071e-08,\n",
      "         1.5790e-09, 1.7709e-07, 6.3675e-08, 2.7967e-07, 4.5890e-12],\n",
      "        [1.1426e-10, 4.7949e-10, 1.0000e+00, 8.1183e-11, 2.1617e-09, 1.2704e-08,\n",
      "         1.5872e-09, 1.8543e-07, 6.7728e-08, 2.6856e-07, 4.8285e-12],\n",
      "        [1.4175e-10, 5.7140e-10, 1.0000e+00, 9.8723e-11, 2.6495e-09, 1.4941e-08,\n",
      "         2.0023e-09, 2.1271e-07, 7.7753e-08, 3.0823e-07, 5.9770e-12],\n",
      "        [1.1626e-10, 4.9722e-10, 1.0000e+00, 8.7133e-11, 2.3389e-09, 1.2871e-08,\n",
      "         1.7697e-09, 1.8871e-07, 7.2587e-08, 2.7438e-07, 5.0660e-12],\n",
      "        [1.2974e-10, 5.5678e-10, 1.0000e+00, 9.5735e-11, 2.6023e-09, 1.3424e-08,\n",
      "         1.8666e-09, 2.0879e-07, 7.8922e-08, 3.0264e-07, 5.7586e-12],\n",
      "        [1.1654e-10, 4.8685e-10, 1.0000e+00, 8.9176e-11, 2.2901e-09, 1.2360e-08,\n",
      "         1.6943e-09, 1.9640e-07, 6.9538e-08, 2.7334e-07, 5.0797e-12],\n",
      "        [1.2816e-10, 5.1364e-10, 1.0000e+00, 9.0211e-11, 2.3931e-09, 1.3476e-08,\n",
      "         1.7937e-09, 1.9660e-07, 7.2055e-08, 2.8164e-07, 5.4153e-12],\n",
      "        [1.1378e-10, 4.8517e-10, 1.0000e+00, 8.4012e-11, 2.2177e-09, 1.2186e-08,\n",
      "         1.6447e-09, 1.9023e-07, 6.5618e-08, 2.6889e-07, 4.9090e-12],\n",
      "        [1.2344e-10, 5.4282e-10, 1.0000e+00, 9.6094e-11, 2.4698e-09, 1.3514e-08,\n",
      "         1.9418e-09, 2.0949e-07, 7.2389e-08, 2.8630e-07, 5.4763e-12],\n",
      "        [1.4039e-10, 5.7994e-10, 1.0000e+00, 1.0191e-10, 2.6498e-09, 1.4575e-08,\n",
      "         1.9639e-09, 2.1420e-07, 7.8733e-08, 3.1299e-07, 6.3574e-12],\n",
      "        [1.1480e-10, 4.7524e-10, 1.0000e+00, 8.3553e-11, 2.1668e-09, 1.2037e-08,\n",
      "         1.5814e-09, 1.8336e-07, 6.4791e-08, 2.7034e-07, 5.0186e-12],\n",
      "        [1.4719e-10, 6.1136e-10, 1.0000e+00, 1.0647e-10, 2.7924e-09, 1.5113e-08,\n",
      "         2.1079e-09, 2.2391e-07, 8.1236e-08, 3.0924e-07, 6.5939e-12],\n",
      "        [1.5065e-10, 6.1937e-10, 1.0000e+00, 1.0862e-10, 2.7792e-09, 1.5275e-08,\n",
      "         2.0244e-09, 2.2638e-07, 8.5531e-08, 3.0906e-07, 6.9490e-12],\n",
      "        [1.0012e-10, 4.5042e-10, 1.0000e+00, 7.7178e-11, 2.0153e-09, 1.1537e-08,\n",
      "         1.4931e-09, 1.7641e-07, 6.3520e-08, 2.5717e-07, 4.2744e-12],\n",
      "        [1.3410e-10, 5.8247e-10, 1.0000e+00, 1.0158e-10, 2.5958e-09, 1.4406e-08,\n",
      "         1.9972e-09, 2.0713e-07, 7.6711e-08, 2.8866e-07, 5.9440e-12],\n",
      "        [1.1039e-10, 4.6872e-10, 1.0000e+00, 7.7633e-11, 2.2253e-09, 1.1544e-08,\n",
      "         1.6451e-09, 1.8240e-07, 6.6662e-08, 2.5275e-07, 4.9087e-12],\n",
      "        [1.2969e-10, 5.3938e-10, 1.0000e+00, 9.0766e-11, 2.4318e-09, 1.3798e-08,\n",
      "         1.8259e-09, 1.9436e-07, 7.4926e-08, 2.8678e-07, 5.6187e-12],\n",
      "        [1.1619e-10, 5.0751e-10, 1.0000e+00, 8.6278e-11, 2.3682e-09, 1.2702e-08,\n",
      "         1.7341e-09, 1.9573e-07, 7.0663e-08, 2.7437e-07, 4.9832e-12],\n",
      "        [9.7911e-11, 4.2247e-10, 1.0000e+00, 7.2654e-11, 1.9208e-09, 1.0904e-08,\n",
      "         1.4718e-09, 1.7127e-07, 6.2198e-08, 2.3649e-07, 4.1642e-12],\n",
      "        [1.1229e-10, 4.6304e-10, 1.0000e+00, 8.0608e-11, 2.1356e-09, 1.2121e-08,\n",
      "         1.6093e-09, 1.8299e-07, 6.6479e-08, 2.6391e-07, 4.8552e-12],\n",
      "        [1.2279e-10, 5.4249e-10, 1.0000e+00, 9.2821e-11, 2.3203e-09, 1.2882e-08,\n",
      "         1.8796e-09, 2.0229e-07, 7.1344e-08, 2.9789e-07, 5.3309e-12],\n",
      "        [1.1494e-10, 4.9585e-10, 1.0000e+00, 8.7009e-11, 2.2728e-09, 1.2727e-08,\n",
      "         1.7352e-09, 1.9476e-07, 6.9769e-08, 2.7668e-07, 5.0516e-12],\n",
      "        [1.3663e-10, 5.6040e-10, 1.0000e+00, 1.0010e-10, 2.5979e-09, 1.4429e-08,\n",
      "         1.9085e-09, 2.1903e-07, 7.8994e-08, 3.1274e-07, 6.0426e-12],\n",
      "        [1.2785e-10, 5.6416e-10, 1.0000e+00, 9.3706e-11, 2.4641e-09, 1.3895e-08,\n",
      "         1.8685e-09, 2.0459e-07, 7.3616e-08, 2.8060e-07, 5.5164e-12],\n",
      "        [1.2461e-10, 5.3962e-10, 1.0000e+00, 9.4693e-11, 2.5353e-09, 1.3481e-08,\n",
      "         1.9282e-09, 1.9691e-07, 7.5975e-08, 2.9412e-07, 5.5999e-12],\n",
      "        [1.1543e-10, 5.0283e-10, 1.0000e+00, 8.9313e-11, 2.3909e-09, 1.2476e-08,\n",
      "         1.7314e-09, 1.9725e-07, 7.0547e-08, 2.8057e-07, 5.2189e-12],\n",
      "        [1.2923e-10, 5.6090e-10, 1.0000e+00, 9.9826e-11, 2.6292e-09, 1.4391e-08,\n",
      "         1.9921e-09, 2.2148e-07, 7.8939e-08, 3.0033e-07, 5.8705e-12],\n",
      "        [1.1808e-10, 4.8866e-10, 1.0000e+00, 8.4209e-11, 2.2738e-09, 1.2047e-08,\n",
      "         1.7068e-09, 1.8759e-07, 6.7604e-08, 2.8244e-07, 4.8071e-12],\n",
      "        [1.6879e-10, 6.6947e-10, 1.0000e+00, 1.2154e-10, 3.0782e-09, 1.6866e-08,\n",
      "         2.3430e-09, 2.4337e-07, 8.7105e-08, 3.5071e-07, 7.5442e-12],\n",
      "        [1.2951e-10, 5.6872e-10, 1.0000e+00, 9.8369e-11, 2.5762e-09, 1.3738e-08,\n",
      "         1.8987e-09, 2.0641e-07, 7.6959e-08, 2.9206e-07, 5.8210e-12],\n",
      "        [1.2347e-10, 5.1559e-10, 1.0000e+00, 8.8598e-11, 2.3225e-09, 1.3220e-08,\n",
      "         1.7585e-09, 1.9851e-07, 7.2542e-08, 2.8429e-07, 5.2235e-12],\n",
      "        [1.2589e-10, 5.4072e-10, 1.0000e+00, 9.5671e-11, 2.5007e-09, 1.3494e-08,\n",
      "         1.9351e-09, 2.1180e-07, 7.6649e-08, 2.9099e-07, 5.7287e-12],\n",
      "        [1.3060e-10, 5.6795e-10, 1.0000e+00, 9.7251e-11, 2.5326e-09, 1.4079e-08,\n",
      "         1.8618e-09, 2.1418e-07, 7.7274e-08, 3.0071e-07, 5.9886e-12],\n",
      "        [1.2655e-10, 5.2244e-10, 1.0000e+00, 9.0894e-11, 2.3756e-09, 1.3378e-08,\n",
      "         1.7621e-09, 2.1028e-07, 7.3058e-08, 2.9667e-07, 5.2865e-12]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   4%|▍         | 3/72 [00:01<00:34,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels : torch.Size([64, 11])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predictions : torch.Size([64, 11])\n",
      "tensor([[3.1411e-08, 8.8743e-08, 9.9998e-01, 2.2144e-08, 3.0030e-07, 1.0782e-06,\n",
      "         2.1763e-07, 7.1111e-06, 3.9548e-06, 9.8523e-06, 3.0643e-09],\n",
      "        [6.0702e-10, 2.2619e-09, 1.0000e+00, 4.5762e-10, 9.5601e-09, 4.8652e-08,\n",
      "         7.3700e-09, 5.6189e-07, 2.3948e-07, 8.1644e-07, 3.2575e-11],\n",
      "        [2.0710e-10, 8.2632e-10, 1.0000e+00, 1.5014e-10, 3.7719e-09, 1.9989e-08,\n",
      "         2.9139e-09, 2.8271e-07, 1.0571e-07, 3.9636e-07, 1.0088e-11],\n",
      "        [1.4172e-10, 5.8375e-10, 1.0000e+00, 1.0445e-10, 2.7245e-09, 1.4930e-08,\n",
      "         1.9612e-09, 2.0936e-07, 7.9335e-08, 3.1767e-07, 6.3544e-12],\n",
      "        [1.8801e-10, 7.4462e-10, 1.0000e+00, 1.3068e-10, 3.4442e-09, 1.8270e-08,\n",
      "         2.5154e-09, 2.6148e-07, 1.0084e-07, 3.8350e-07, 8.1707e-12],\n",
      "        [1.6627e-10, 6.3799e-10, 1.0000e+00, 1.1778e-10, 3.0048e-09, 1.6455e-08,\n",
      "         2.2606e-09, 2.3600e-07, 8.9476e-08, 3.3534e-07, 6.9560e-12],\n",
      "        [1.2267e-10, 5.3196e-10, 1.0000e+00, 9.4637e-11, 2.4980e-09, 1.3541e-08,\n",
      "         1.8857e-09, 2.0339e-07, 7.6761e-08, 3.0024e-07, 5.7176e-12],\n",
      "        [1.4358e-10, 5.9668e-10, 1.0000e+00, 1.0351e-10, 2.6418e-09, 1.4831e-08,\n",
      "         2.0473e-09, 2.1935e-07, 7.7712e-08, 3.0607e-07, 6.2363e-12],\n",
      "        [1.4305e-10, 5.8571e-10, 1.0000e+00, 1.0477e-10, 2.7678e-09, 1.4940e-08,\n",
      "         2.0851e-09, 2.1891e-07, 8.1785e-08, 3.2697e-07, 6.2371e-12],\n",
      "        [1.4829e-10, 6.4610e-10, 1.0000e+00, 1.1246e-10, 2.8231e-09, 1.6543e-08,\n",
      "         2.2028e-09, 2.3402e-07, 8.3335e-08, 3.5089e-07, 6.8542e-12],\n",
      "        [1.5357e-10, 6.5578e-10, 1.0000e+00, 1.1369e-10, 2.9268e-09, 1.6145e-08,\n",
      "         2.2034e-09, 2.2410e-07, 8.8099e-08, 3.4278e-07, 7.1034e-12],\n",
      "        [1.1895e-10, 5.4141e-10, 1.0000e+00, 9.2902e-11, 2.4417e-09, 1.3311e-08,\n",
      "         1.8427e-09, 1.9690e-07, 7.5732e-08, 3.0982e-07, 5.3224e-12],\n",
      "        [1.3849e-10, 5.9805e-10, 1.0000e+00, 1.0143e-10, 2.6635e-09, 1.4753e-08,\n",
      "         2.0602e-09, 2.0902e-07, 7.9920e-08, 3.1548e-07, 5.9604e-12],\n",
      "        [1.1556e-10, 4.9737e-10, 1.0000e+00, 8.5235e-11, 2.3804e-09, 1.3096e-08,\n",
      "         1.7690e-09, 1.9864e-07, 7.3492e-08, 2.9981e-07, 5.0778e-12],\n",
      "        [1.4061e-10, 6.0433e-10, 1.0000e+00, 1.0561e-10, 2.7805e-09, 1.4945e-08,\n",
      "         2.0527e-09, 2.2823e-07, 8.4669e-08, 3.3170e-07, 6.2577e-12],\n",
      "        [1.3553e-10, 5.5746e-10, 1.0000e+00, 9.7936e-11, 2.6215e-09, 1.4255e-08,\n",
      "         1.9353e-09, 2.0925e-07, 7.9577e-08, 3.1954e-07, 5.9377e-12],\n",
      "        [1.1126e-10, 4.7355e-10, 1.0000e+00, 8.0413e-11, 2.2360e-09, 1.2657e-08,\n",
      "         1.5803e-09, 1.7732e-07, 6.7861e-08, 2.7722e-07, 4.8354e-12],\n",
      "        [1.9041e-10, 7.8636e-10, 1.0000e+00, 1.3300e-10, 3.4359e-09, 1.8879e-08,\n",
      "         2.4861e-09, 2.7583e-07, 9.8467e-08, 3.9814e-07, 8.7017e-12],\n",
      "        [1.4759e-10, 5.9800e-10, 1.0000e+00, 1.0559e-10, 2.7284e-09, 1.4912e-08,\n",
      "         2.0906e-09, 2.3004e-07, 8.1009e-08, 3.2222e-07, 6.3508e-12],\n",
      "        [1.4177e-10, 5.8485e-10, 1.0000e+00, 1.0245e-10, 2.6411e-09, 1.5094e-08,\n",
      "         1.9968e-09, 2.1984e-07, 8.1209e-08, 3.2462e-07, 6.0532e-12],\n",
      "        [1.5420e-10, 6.3344e-10, 1.0000e+00, 1.1189e-10, 3.0259e-09, 1.6048e-08,\n",
      "         2.2032e-09, 2.4219e-07, 8.8653e-08, 3.3542e-07, 6.6435e-12],\n",
      "        [1.1501e-10, 5.1782e-10, 1.0000e+00, 8.8131e-11, 2.3753e-09, 1.2752e-08,\n",
      "         1.7474e-09, 1.9251e-07, 7.0776e-08, 2.8967e-07, 4.9882e-12],\n",
      "        [1.5150e-10, 6.2350e-10, 1.0000e+00, 1.0800e-10, 2.9023e-09, 1.5553e-08,\n",
      "         2.1323e-09, 2.2799e-07, 8.4623e-08, 3.3818e-07, 6.4150e-12],\n",
      "        [1.5891e-10, 6.3870e-10, 1.0000e+00, 1.1235e-10, 2.9327e-09, 1.6018e-08,\n",
      "         2.2304e-09, 2.3840e-07, 8.7963e-08, 3.4395e-07, 7.0090e-12],\n",
      "        [1.5546e-10, 6.3849e-10, 1.0000e+00, 1.0961e-10, 2.8337e-09, 1.5830e-08,\n",
      "         2.1860e-09, 2.4095e-07, 8.4471e-08, 3.6035e-07, 6.7714e-12],\n",
      "        [1.6412e-10, 6.8079e-10, 1.0000e+00, 1.2059e-10, 3.0629e-09, 1.7035e-08,\n",
      "         2.3300e-09, 2.3241e-07, 8.5240e-08, 3.4434e-07, 7.4320e-12],\n",
      "        [1.5009e-10, 6.1713e-10, 1.0000e+00, 1.1286e-10, 2.9428e-09, 1.5974e-08,\n",
      "         2.1777e-09, 2.3973e-07, 8.7241e-08, 3.4324e-07, 6.7949e-12],\n",
      "        [1.6610e-10, 6.7274e-10, 1.0000e+00, 1.1830e-10, 3.0689e-09, 1.6600e-08,\n",
      "         2.3201e-09, 2.4022e-07, 9.3679e-08, 3.4644e-07, 7.1492e-12],\n",
      "        [1.4666e-10, 6.4136e-10, 1.0000e+00, 1.0725e-10, 2.8610e-09, 1.5461e-08,\n",
      "         2.1087e-09, 2.2642e-07, 8.1863e-08, 3.3432e-07, 6.5514e-12],\n",
      "        [1.2816e-10, 5.2841e-10, 1.0000e+00, 9.3245e-11, 2.5117e-09, 1.4114e-08,\n",
      "         1.8550e-09, 2.0832e-07, 7.5770e-08, 3.0348e-07, 5.7033e-12],\n",
      "        [1.0812e-10, 4.8564e-10, 1.0000e+00, 8.0081e-11, 2.2569e-09, 1.2574e-08,\n",
      "         1.6442e-09, 1.8374e-07, 6.8471e-08, 2.7435e-07, 4.9242e-12],\n",
      "        [1.2703e-10, 5.5219e-10, 1.0000e+00, 9.5113e-11, 2.5411e-09, 1.3714e-08,\n",
      "         1.9030e-09, 1.9982e-07, 7.4552e-08, 3.0010e-07, 5.7173e-12],\n",
      "        [1.3166e-10, 5.7440e-10, 1.0000e+00, 9.6876e-11, 2.5778e-09, 1.3732e-08,\n",
      "         2.0057e-09, 2.1354e-07, 8.0570e-08, 3.2215e-07, 5.7031e-12],\n",
      "        [1.4729e-10, 6.2461e-10, 1.0000e+00, 1.1068e-10, 2.8209e-09, 1.5587e-08,\n",
      "         2.1415e-09, 2.2021e-07, 8.6868e-08, 3.4003e-07, 6.4874e-12],\n",
      "        [1.4904e-10, 6.3880e-10, 1.0000e+00, 1.1339e-10, 2.9132e-09, 1.5178e-08,\n",
      "         2.1730e-09, 2.2731e-07, 8.5189e-08, 3.3005e-07, 6.6689e-12],\n",
      "        [1.2247e-10, 5.3607e-10, 1.0000e+00, 9.0419e-11, 2.3882e-09, 1.3274e-08,\n",
      "         1.8908e-09, 2.0058e-07, 7.3656e-08, 3.1109e-07, 5.6119e-12],\n",
      "        [1.2807e-10, 5.1349e-10, 1.0000e+00, 9.0694e-11, 2.3512e-09, 1.3526e-08,\n",
      "         1.7913e-09, 2.0206e-07, 7.3957e-08, 3.1103e-07, 5.3302e-12],\n",
      "        [1.2157e-10, 5.0352e-10, 1.0000e+00, 8.5503e-11, 2.4089e-09, 1.2814e-08,\n",
      "         1.7905e-09, 1.9295e-07, 7.1899e-08, 2.9300e-07, 5.3371e-12],\n",
      "        [1.3988e-10, 5.6552e-10, 1.0000e+00, 9.9408e-11, 2.7404e-09, 1.4679e-08,\n",
      "         2.0055e-09, 2.1856e-07, 8.0609e-08, 3.1331e-07, 6.0538e-12],\n",
      "        [1.4044e-10, 5.6916e-10, 1.0000e+00, 1.0578e-10, 2.6868e-09, 1.4396e-08,\n",
      "         2.0738e-09, 2.1087e-07, 7.8035e-08, 3.3636e-07, 5.6686e-12],\n",
      "        [1.5064e-10, 6.2886e-10, 1.0000e+00, 1.1152e-10, 2.9644e-09, 1.5223e-08,\n",
      "         2.1553e-09, 2.2687e-07, 8.5774e-08, 3.5430e-07, 6.5360e-12],\n",
      "        [1.3070e-10, 5.4329e-10, 1.0000e+00, 9.6499e-11, 2.5771e-09, 1.3704e-08,\n",
      "         1.8709e-09, 2.0538e-07, 7.6051e-08, 3.0977e-07, 5.7892e-12],\n",
      "        [1.1257e-10, 4.7440e-10, 1.0000e+00, 8.0692e-11, 2.2467e-09, 1.2671e-08,\n",
      "         1.6699e-09, 1.8337e-07, 6.8048e-08, 2.7954e-07, 4.9029e-12],\n",
      "        [1.1781e-10, 5.0639e-10, 1.0000e+00, 8.7641e-11, 2.3344e-09, 1.2703e-08,\n",
      "         1.6768e-09, 1.8666e-07, 7.0805e-08, 2.8886e-07, 5.1115e-12],\n",
      "        [1.5228e-10, 6.4020e-10, 1.0000e+00, 1.1371e-10, 2.9263e-09, 1.5669e-08,\n",
      "         2.1904e-09, 2.3751e-07, 8.6972e-08, 3.5019e-07, 6.7918e-12],\n",
      "        [1.2928e-10, 5.6512e-10, 1.0000e+00, 9.9870e-11, 2.6299e-09, 1.4357e-08,\n",
      "         1.8968e-09, 2.0471e-07, 7.7321e-08, 3.1566e-07, 5.6672e-12],\n",
      "        [1.3415e-10, 5.6887e-10, 1.0000e+00, 9.9330e-11, 2.6843e-09, 1.4542e-08,\n",
      "         1.9577e-09, 2.0507e-07, 7.9843e-08, 3.2751e-07, 6.1841e-12],\n",
      "        [1.3882e-10, 5.8484e-10, 1.0000e+00, 1.0429e-10, 2.6746e-09, 1.4798e-08,\n",
      "         2.0686e-09, 2.1518e-07, 8.0132e-08, 3.3839e-07, 6.1939e-12],\n",
      "        [1.2330e-10, 5.4648e-10, 1.0000e+00, 9.1807e-11, 2.5118e-09, 1.3488e-08,\n",
      "         1.8208e-09, 1.9894e-07, 7.4489e-08, 3.0362e-07, 5.3780e-12],\n",
      "        [1.1810e-10, 5.2065e-10, 1.0000e+00, 9.0867e-11, 2.4364e-09, 1.2535e-08,\n",
      "         1.7936e-09, 2.0826e-07, 7.5850e-08, 2.9300e-07, 5.3444e-12],\n",
      "        [1.4183e-10, 5.8902e-10, 1.0000e+00, 1.0423e-10, 2.6683e-09, 1.4828e-08,\n",
      "         2.0683e-09, 2.2029e-07, 8.2224e-08, 3.2045e-07, 6.3832e-12],\n",
      "        [1.2544e-10, 5.4097e-10, 1.0000e+00, 9.8234e-11, 2.5138e-09, 1.3904e-08,\n",
      "         1.9018e-09, 2.1588e-07, 7.7884e-08, 3.1575e-07, 5.7398e-12],\n",
      "        [1.2979e-10, 5.3415e-10, 1.0000e+00, 9.3138e-11, 2.5164e-09, 1.3908e-08,\n",
      "         1.8776e-09, 2.1492e-07, 7.3788e-08, 3.1578e-07, 5.4870e-12],\n",
      "        [1.4933e-10, 6.1147e-10, 1.0000e+00, 1.1279e-10, 2.7573e-09, 1.5445e-08,\n",
      "         2.1049e-09, 2.2509e-07, 8.2470e-08, 3.4363e-07, 6.5807e-12],\n",
      "        [1.6744e-10, 7.0770e-10, 1.0000e+00, 1.2556e-10, 3.1626e-09, 1.7053e-08,\n",
      "         2.3947e-09, 2.5404e-07, 9.3669e-08, 3.5219e-07, 7.4495e-12],\n",
      "        [1.4364e-10, 6.2898e-10, 1.0000e+00, 1.1081e-10, 2.9268e-09, 1.5432e-08,\n",
      "         2.0835e-09, 2.2413e-07, 8.7919e-08, 3.3752e-07, 6.5649e-12],\n",
      "        [1.0507e-10, 4.7204e-10, 1.0000e+00, 8.0539e-11, 2.2408e-09, 1.1970e-08,\n",
      "         1.6101e-09, 1.7485e-07, 6.7096e-08, 2.7063e-07, 4.5777e-12],\n",
      "        [1.2021e-10, 4.7974e-10, 1.0000e+00, 8.8935e-11, 2.2678e-09, 1.2830e-08,\n",
      "         1.7234e-09, 1.9821e-07, 6.9418e-08, 2.9211e-07, 5.1242e-12],\n",
      "        [1.3668e-10, 5.8081e-10, 1.0000e+00, 1.0391e-10, 2.5489e-09, 1.4036e-08,\n",
      "         1.9557e-09, 2.0857e-07, 7.8076e-08, 3.1866e-07, 6.1344e-12],\n",
      "        [1.2088e-10, 5.0953e-10, 1.0000e+00, 9.0537e-11, 2.4094e-09, 1.3064e-08,\n",
      "         1.8818e-09, 1.9042e-07, 7.1691e-08, 2.7943e-07, 5.3800e-12],\n",
      "        [1.1642e-10, 4.9475e-10, 1.0000e+00, 8.8324e-11, 2.2609e-09, 1.2587e-08,\n",
      "         1.7159e-09, 1.9213e-07, 6.8940e-08, 2.8138e-07, 5.1248e-12],\n",
      "        [1.4043e-10, 5.9395e-10, 1.0000e+00, 1.0241e-10, 2.6488e-09, 1.4929e-08,\n",
      "         2.0298e-09, 2.0904e-07, 7.9996e-08, 3.2215e-07, 6.1503e-12],\n",
      "        [1.4533e-10, 6.0814e-10, 1.0000e+00, 1.0646e-10, 2.7670e-09, 1.5372e-08,\n",
      "         2.0498e-09, 2.1601e-07, 7.9371e-08, 3.1692e-07, 6.4525e-12],\n",
      "        [1.4239e-10, 6.0208e-10, 1.0000e+00, 1.0705e-10, 2.7735e-09, 1.4777e-08,\n",
      "         2.0819e-09, 2.2586e-07, 8.2721e-08, 3.2907e-07, 6.2981e-12]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   6%|▌         | 4/72 [00:01<00:34,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels : torch.Size([64, 11])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "predictions : torch.Size([64, 11])\n",
      "tensor([[5.3779e-08, 1.4370e-07, 9.9997e-01, 3.7341e-08, 4.5342e-07, 1.6803e-06,\n",
      "         3.5583e-07, 1.0504e-05, 5.9520e-06, 1.3381e-05, 5.2939e-09],\n",
      "        [9.4474e-10, 3.2948e-09, 1.0000e+00, 6.4188e-10, 1.3417e-08, 6.7825e-08,\n",
      "         1.0293e-08, 7.4518e-07, 3.0387e-07, 1.0497e-06, 5.4046e-11],\n",
      "        [2.5915e-10, 9.9732e-10, 1.0000e+00, 1.8956e-10, 4.7589e-09, 2.4717e-08,\n",
      "         3.4892e-09, 3.3733e-07, 1.3030e-07, 4.9652e-07, 1.2430e-11],\n",
      "        [1.7252e-10, 7.2002e-10, 1.0000e+00, 1.2629e-10, 3.2556e-09, 1.7798e-08,\n",
      "         2.5300e-09, 2.6819e-07, 9.3888e-08, 4.0141e-07, 7.5812e-12],\n",
      "        [1.9061e-10, 7.7861e-10, 1.0000e+00, 1.3557e-10, 3.5256e-09, 1.8871e-08,\n",
      "         2.6645e-09, 2.8315e-07, 1.0212e-07, 4.0166e-07, 8.4464e-12],\n",
      "        [1.6100e-10, 6.7439e-10, 1.0000e+00, 1.1874e-10, 3.1342e-09, 1.6784e-08,\n",
      "         2.3673e-09, 2.6497e-07, 9.0372e-08, 3.6850e-07, 7.2670e-12],\n",
      "        [1.6556e-10, 6.8776e-10, 1.0000e+00, 1.2406e-10, 3.0903e-09, 1.6887e-08,\n",
      "         2.3606e-09, 2.4555e-07, 9.3049e-08, 3.9619e-07, 7.3523e-12],\n",
      "        [1.5295e-10, 6.2685e-10, 1.0000e+00, 1.1166e-10, 2.8562e-09, 1.5388e-08,\n",
      "         2.1044e-09, 2.3485e-07, 8.9445e-08, 3.7453e-07, 6.7595e-12],\n",
      "        [1.3046e-10, 5.7800e-10, 1.0000e+00, 9.7777e-11, 2.5931e-09, 1.4589e-08,\n",
      "         1.9608e-09, 2.1561e-07, 8.1410e-08, 3.3610e-07, 6.0614e-12],\n",
      "        [1.6363e-10, 7.0798e-10, 1.0000e+00, 1.2155e-10, 3.1027e-09, 1.7846e-08,\n",
      "         2.2952e-09, 2.5879e-07, 9.4457e-08, 4.0586e-07, 7.5958e-12],\n",
      "        [1.6485e-10, 6.8790e-10, 1.0000e+00, 1.1919e-10, 3.0449e-09, 1.6859e-08,\n",
      "         2.3288e-09, 2.5715e-07, 9.3129e-08, 3.7882e-07, 7.2288e-12],\n",
      "        [1.4937e-10, 6.5266e-10, 1.0000e+00, 1.1270e-10, 2.9456e-09, 1.6328e-08,\n",
      "         2.1516e-09, 2.5178e-07, 8.6901e-08, 3.6927e-07, 6.5394e-12],\n",
      "        [1.3806e-10, 5.8123e-10, 1.0000e+00, 9.9154e-11, 2.6182e-09, 1.4808e-08,\n",
      "         1.9735e-09, 2.3735e-07, 8.3438e-08, 3.4100e-07, 5.8656e-12],\n",
      "        [1.5464e-10, 6.3134e-10, 1.0000e+00, 1.1433e-10, 2.8470e-09, 1.6384e-08,\n",
      "         2.2017e-09, 2.4895e-07, 8.8432e-08, 3.5815e-07, 6.2526e-12],\n",
      "        [1.4265e-10, 5.9950e-10, 1.0000e+00, 9.8923e-11, 2.7547e-09, 1.4598e-08,\n",
      "         2.0228e-09, 2.2618e-07, 8.0848e-08, 3.3336e-07, 6.0334e-12],\n",
      "        [1.4054e-10, 6.0429e-10, 1.0000e+00, 1.0190e-10, 2.6617e-09, 1.4518e-08,\n",
      "         2.0406e-09, 2.2032e-07, 8.2183e-08, 3.3639e-07, 6.0603e-12],\n",
      "        [1.3222e-10, 5.5897e-10, 1.0000e+00, 1.0022e-10, 2.6251e-09, 1.4811e-08,\n",
      "         1.9801e-09, 2.2619e-07, 7.8690e-08, 3.3585e-07, 5.6409e-12],\n",
      "        [1.6688e-10, 6.8776e-10, 1.0000e+00, 1.2203e-10, 3.1502e-09, 1.7207e-08,\n",
      "         2.2879e-09, 2.5802e-07, 8.9370e-08, 3.7995e-07, 7.2026e-12],\n",
      "        [1.5661e-10, 6.3684e-10, 1.0000e+00, 1.1466e-10, 2.9612e-09, 1.5971e-08,\n",
      "         2.2198e-09, 2.5325e-07, 8.8535e-08, 3.7459e-07, 6.7125e-12],\n",
      "        [1.7717e-10, 7.5942e-10, 1.0000e+00, 1.3631e-10, 3.4380e-09, 1.8505e-08,\n",
      "         2.6509e-09, 2.7161e-07, 1.0119e-07, 4.0256e-07, 8.3180e-12],\n",
      "        [1.5636e-10, 6.4831e-10, 1.0000e+00, 1.1351e-10, 2.9624e-09, 1.6539e-08,\n",
      "         2.2249e-09, 2.4114e-07, 8.7120e-08, 3.7244e-07, 7.0432e-12],\n",
      "        [1.4780e-10, 6.1421e-10, 1.0000e+00, 1.0800e-10, 2.7252e-09, 1.4986e-08,\n",
      "         2.0638e-09, 2.3229e-07, 8.2565e-08, 3.4044e-07, 6.2936e-12],\n",
      "        [1.5996e-10, 6.7807e-10, 1.0000e+00, 1.1957e-10, 3.1164e-09, 1.6915e-08,\n",
      "         2.3501e-09, 2.5816e-07, 9.3936e-08, 3.7367e-07, 7.1592e-12],\n",
      "        [1.5164e-10, 6.4794e-10, 1.0000e+00, 1.1029e-10, 2.9125e-09, 1.5985e-08,\n",
      "         2.2363e-09, 2.5078e-07, 8.6932e-08, 3.5763e-07, 6.7370e-12],\n",
      "        [1.3837e-10, 5.8028e-10, 1.0000e+00, 9.6401e-11, 2.6036e-09, 1.4573e-08,\n",
      "         2.0101e-09, 2.2592e-07, 8.1654e-08, 3.5283e-07, 6.0239e-12],\n",
      "        [1.4199e-10, 6.0556e-10, 1.0000e+00, 1.0509e-10, 2.7672e-09, 1.4335e-08,\n",
      "         2.0696e-09, 2.3494e-07, 8.0675e-08, 3.4614e-07, 6.2517e-12],\n",
      "        [1.5415e-10, 6.3845e-10, 1.0000e+00, 1.1391e-10, 3.0139e-09, 1.6174e-08,\n",
      "         2.2522e-09, 2.3565e-07, 8.3670e-08, 3.5469e-07, 6.9797e-12],\n",
      "        [1.8034e-10, 7.3855e-10, 1.0000e+00, 1.3351e-10, 3.4537e-09, 1.8411e-08,\n",
      "         2.6214e-09, 2.6809e-07, 9.5764e-08, 4.1269e-07, 7.6665e-12],\n",
      "        [1.5148e-10, 6.3515e-10, 1.0000e+00, 1.1176e-10, 2.8352e-09, 1.6230e-08,\n",
      "         2.1691e-09, 2.4191e-07, 8.5103e-08, 3.6535e-07, 6.9559e-12],\n",
      "        [1.3290e-10, 5.6774e-10, 1.0000e+00, 9.9680e-11, 2.6259e-09, 1.4201e-08,\n",
      "         1.8808e-09, 2.2842e-07, 8.2802e-08, 3.3715e-07, 6.1206e-12],\n",
      "        [1.8205e-10, 7.7672e-10, 1.0000e+00, 1.3575e-10, 3.4452e-09, 1.8516e-08,\n",
      "         2.5963e-09, 2.7761e-07, 1.0345e-07, 4.1147e-07, 8.4168e-12],\n",
      "        [1.6574e-10, 6.7928e-10, 1.0000e+00, 1.2178e-10, 3.2152e-09, 1.7546e-08,\n",
      "         2.2527e-09, 2.7079e-07, 9.2441e-08, 3.6322e-07, 7.3375e-12],\n",
      "        [1.7560e-10, 6.9957e-10, 1.0000e+00, 1.3131e-10, 3.4582e-09, 1.8118e-08,\n",
      "         2.5699e-09, 2.8275e-07, 9.9389e-08, 3.9355e-07, 7.8569e-12],\n",
      "        [1.7125e-10, 7.1895e-10, 1.0000e+00, 1.2355e-10, 3.2832e-09, 1.7726e-08,\n",
      "         2.4936e-09, 2.6036e-07, 9.5916e-08, 3.9337e-07, 7.6618e-12],\n",
      "        [1.6025e-10, 6.8069e-10, 1.0000e+00, 1.2166e-10, 3.1624e-09, 1.7195e-08,\n",
      "         2.3192e-09, 2.5863e-07, 9.2099e-08, 3.7568e-07, 7.3273e-12],\n",
      "        [1.3810e-10, 6.0401e-10, 1.0000e+00, 1.0266e-10, 2.6758e-09, 1.4873e-08,\n",
      "         2.0762e-09, 2.3396e-07, 8.4478e-08, 3.5462e-07, 5.9082e-12],\n",
      "        [1.9128e-10, 7.8033e-10, 1.0000e+00, 1.3755e-10, 3.4442e-09, 1.8975e-08,\n",
      "         2.7177e-09, 2.8237e-07, 1.0151e-07, 4.0944e-07, 8.3405e-12],\n",
      "        [1.7458e-10, 7.3318e-10, 1.0000e+00, 1.3229e-10, 3.2728e-09, 1.8726e-08,\n",
      "         2.4254e-09, 2.7014e-07, 9.8937e-08, 4.1011e-07, 7.9353e-12],\n",
      "        [2.0022e-10, 8.2793e-10, 1.0000e+00, 1.4643e-10, 3.6444e-09, 1.9384e-08,\n",
      "         2.7177e-09, 3.0673e-07, 1.0642e-07, 4.5129e-07, 8.8216e-12],\n",
      "        [1.8166e-10, 7.5022e-10, 1.0000e+00, 1.3472e-10, 3.4319e-09, 1.8431e-08,\n",
      "         2.5901e-09, 2.7918e-07, 9.8479e-08, 4.0863e-07, 8.2205e-12],\n",
      "        [1.5074e-10, 6.2436e-10, 1.0000e+00, 1.1168e-10, 2.9108e-09, 1.5604e-08,\n",
      "         2.1945e-09, 2.4925e-07, 8.4507e-08, 3.6182e-07, 6.2123e-12],\n",
      "        [1.6523e-10, 6.9545e-10, 1.0000e+00, 1.2243e-10, 3.0373e-09, 1.6892e-08,\n",
      "         2.3932e-09, 2.6173e-07, 9.3076e-08, 3.8372e-07, 7.4337e-12],\n",
      "        [1.8333e-10, 7.5925e-10, 1.0000e+00, 1.3952e-10, 3.4579e-09, 1.8597e-08,\n",
      "         2.6434e-09, 2.6712e-07, 1.0092e-07, 3.9869e-07, 8.1304e-12],\n",
      "        [1.3438e-10, 5.7370e-10, 1.0000e+00, 9.9210e-11, 2.7187e-09, 1.4604e-08,\n",
      "         2.0219e-09, 2.3111e-07, 8.3705e-08, 3.4353e-07, 6.0117e-12],\n",
      "        [1.6440e-10, 6.6633e-10, 1.0000e+00, 1.1673e-10, 3.0687e-09, 1.6917e-08,\n",
      "         2.3313e-09, 2.5670e-07, 8.9823e-08, 3.7074e-07, 7.0858e-12],\n",
      "        [1.8552e-10, 7.5158e-10, 1.0000e+00, 1.3486e-10, 3.4053e-09, 1.8235e-08,\n",
      "         2.5328e-09, 2.9496e-07, 9.9506e-08, 4.0465e-07, 8.2380e-12],\n",
      "        [1.9674e-10, 7.9299e-10, 1.0000e+00, 1.3999e-10, 3.5644e-09, 1.9051e-08,\n",
      "         2.6322e-09, 2.9053e-07, 1.0749e-07, 4.0515e-07, 8.9333e-12],\n",
      "        [1.7464e-10, 7.3576e-10, 1.0000e+00, 1.3011e-10, 3.3368e-09, 1.8219e-08,\n",
      "         2.5105e-09, 2.6928e-07, 9.9561e-08, 4.1044e-07, 8.0258e-12],\n",
      "        [1.6993e-10, 7.3382e-10, 1.0000e+00, 1.2759e-10, 3.1726e-09, 1.7531e-08,\n",
      "         2.4778e-09, 2.5570e-07, 9.3319e-08, 3.7652e-07, 7.8314e-12],\n",
      "        [1.5428e-10, 6.6801e-10, 1.0000e+00, 1.1476e-10, 3.0201e-09, 1.6051e-08,\n",
      "         2.2759e-09, 2.4423e-07, 8.7003e-08, 3.6516e-07, 7.0309e-12],\n",
      "        [2.2529e-10, 9.0559e-10, 1.0000e+00, 1.6348e-10, 4.0958e-09, 2.1878e-08,\n",
      "         2.9983e-09, 3.2498e-07, 1.1135e-07, 4.6794e-07, 1.0604e-11],\n",
      "        [1.8170e-10, 7.4573e-10, 1.0000e+00, 1.2817e-10, 3.3329e-09, 1.8526e-08,\n",
      "         2.4987e-09, 2.7525e-07, 9.7302e-08, 3.9379e-07, 8.1759e-12],\n",
      "        [1.6424e-10, 6.7957e-10, 1.0000e+00, 1.1763e-10, 3.1435e-09, 1.7172e-08,\n",
      "         2.3144e-09, 2.5747e-07, 9.4150e-08, 3.7667e-07, 7.5001e-12],\n",
      "        [1.5509e-10, 6.4330e-10, 1.0000e+00, 1.1291e-10, 2.9292e-09, 1.6667e-08,\n",
      "         2.2422e-09, 2.4516e-07, 8.8360e-08, 3.6168e-07, 6.9385e-12],\n",
      "        [1.4812e-10, 6.0188e-10, 1.0000e+00, 1.0755e-10, 2.7903e-09, 1.5416e-08,\n",
      "         2.1638e-09, 2.3747e-07, 8.4273e-08, 3.5885e-07, 6.5786e-12],\n",
      "        [1.7109e-10, 7.0644e-10, 1.0000e+00, 1.2055e-10, 3.1913e-09, 1.7865e-08,\n",
      "         2.4002e-09, 2.6209e-07, 9.6395e-08, 3.9552e-07, 7.4052e-12],\n",
      "        [1.6805e-10, 6.8562e-10, 1.0000e+00, 1.2216e-10, 3.2297e-09, 1.7527e-08,\n",
      "         2.4137e-09, 2.6957e-07, 9.3917e-08, 3.9321e-07, 7.5320e-12],\n",
      "        [1.7280e-10, 7.0772e-10, 1.0000e+00, 1.2832e-10, 3.2252e-09, 1.7639e-08,\n",
      "         2.4705e-09, 2.8090e-07, 9.3768e-08, 3.8633e-07, 7.6178e-12],\n",
      "        [1.6556e-10, 6.8782e-10, 1.0000e+00, 1.1604e-10, 3.3144e-09, 1.6813e-08,\n",
      "         2.3838e-09, 2.4949e-07, 8.7978e-08, 3.7408e-07, 7.1248e-12],\n",
      "        [1.6163e-10, 6.5520e-10, 1.0000e+00, 1.1670e-10, 3.0478e-09, 1.7395e-08,\n",
      "         2.1984e-09, 2.5892e-07, 9.0755e-08, 3.8965e-07, 7.0615e-12],\n",
      "        [1.9642e-10, 8.1549e-10, 1.0000e+00, 1.4500e-10, 3.5725e-09, 1.8986e-08,\n",
      "         2.6068e-09, 2.9216e-07, 1.0390e-07, 4.0706e-07, 8.5172e-12],\n",
      "        [1.6491e-10, 6.9087e-10, 1.0000e+00, 1.2289e-10, 3.1737e-09, 1.7460e-08,\n",
      "         2.3376e-09, 2.5722e-07, 9.3015e-08, 3.7939e-07, 7.5315e-12],\n",
      "        [1.8031e-10, 7.5917e-10, 1.0000e+00, 1.3347e-10, 3.3204e-09, 1.8548e-08,\n",
      "         2.5690e-09, 2.7600e-07, 9.8850e-08, 3.9398e-07, 8.2254e-12],\n",
      "        [1.5071e-10, 6.3265e-10, 1.0000e+00, 1.0847e-10, 2.8371e-09, 1.6030e-08,\n",
      "         2.1755e-09, 2.4924e-07, 8.4412e-08, 3.5367e-07, 6.6680e-12]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   7%|▋         | 5/72 [00:02<00:34,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels : torch.Size([64, 11])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predictions : torch.Size([64, 11])\n",
      "tensor([[5.2110e-08, 1.4578e-07, 9.9997e-01, 3.7205e-08, 4.5381e-07, 1.7151e-06,\n",
      "         3.5554e-07, 1.0830e-05, 6.1142e-06, 1.4554e-05, 5.1716e-09],\n",
      "        [7.2765e-10, 2.6862e-09, 1.0000e+00, 5.2654e-10, 1.1556e-08, 5.7610e-08,\n",
      "         8.5285e-09, 6.7720e-07, 2.8599e-07, 9.6877e-07, 3.9134e-11],\n",
      "        [2.6541e-10, 1.0993e-09, 1.0000e+00, 1.9575e-10, 4.8621e-09, 2.5643e-08,\n",
      "         3.6375e-09, 3.6413e-07, 1.3408e-07, 5.3629e-07, 1.2755e-11],\n",
      "        [2.6238e-10, 1.0322e-09, 1.0000e+00, 1.8799e-10, 4.9481e-09, 2.5337e-08,\n",
      "         3.5769e-09, 3.6656e-07, 1.3731e-07, 5.2794e-07, 1.2073e-11],\n",
      "        [2.6065e-10, 1.0204e-09, 1.0000e+00, 1.8956e-10, 4.7785e-09, 2.5329e-08,\n",
      "         3.6703e-09, 3.9634e-07, 1.3866e-07, 5.3530e-07, 1.2212e-11],\n",
      "        [2.2124e-10, 9.0870e-10, 1.0000e+00, 1.6951e-10, 4.0887e-09, 2.2027e-08,\n",
      "         3.1433e-09, 3.4979e-07, 1.2082e-07, 4.8630e-07, 1.0032e-11],\n",
      "        [2.0834e-10, 9.0972e-10, 1.0000e+00, 1.6131e-10, 4.1532e-09, 2.1646e-08,\n",
      "         3.0022e-09, 3.4435e-07, 1.1924e-07, 4.8005e-07, 9.4052e-12],\n",
      "        [2.5037e-10, 1.0549e-09, 1.0000e+00, 1.8961e-10, 5.0395e-09, 2.4930e-08,\n",
      "         3.6476e-09, 3.8293e-07, 1.3888e-07, 5.3623e-07, 1.2117e-11],\n",
      "        [1.7178e-10, 7.2615e-10, 1.0000e+00, 1.2785e-10, 3.2396e-09, 1.8031e-08,\n",
      "         2.5445e-09, 2.9789e-07, 1.0161e-07, 4.0739e-07, 7.5262e-12],\n",
      "        [1.9638e-10, 8.1804e-10, 1.0000e+00, 1.4694e-10, 3.6656e-09, 1.9884e-08,\n",
      "         2.7569e-09, 3.1578e-07, 1.1265e-07, 4.6156e-07, 9.0496e-12],\n",
      "        [1.8233e-10, 7.5877e-10, 1.0000e+00, 1.3166e-10, 3.4056e-09, 1.8452e-08,\n",
      "         2.6022e-09, 3.0119e-07, 1.0186e-07, 4.1379e-07, 7.6941e-12],\n",
      "        [2.2459e-10, 9.1023e-10, 1.0000e+00, 1.6636e-10, 4.1140e-09, 2.3128e-08,\n",
      "         3.0419e-09, 3.4266e-07, 1.2551e-07, 4.9735e-07, 1.0536e-11],\n",
      "        [1.9816e-10, 8.5175e-10, 1.0000e+00, 1.4267e-10, 3.8447e-09, 2.0130e-08,\n",
      "         2.7845e-09, 3.3190e-07, 1.1188e-07, 4.6997e-07, 8.6475e-12],\n",
      "        [1.9270e-10, 8.2138e-10, 1.0000e+00, 1.4389e-10, 3.5977e-09, 1.9384e-08,\n",
      "         2.6597e-09, 3.1596e-07, 1.1036e-07, 4.4339e-07, 8.3501e-12],\n",
      "        [1.7800e-10, 7.3927e-10, 1.0000e+00, 1.2736e-10, 3.3503e-09, 1.8188e-08,\n",
      "         2.5170e-09, 2.7617e-07, 9.9904e-08, 4.1278e-07, 7.6665e-12],\n",
      "        [1.9507e-10, 7.9557e-10, 1.0000e+00, 1.4087e-10, 3.7480e-09, 2.0358e-08,\n",
      "         2.7918e-09, 3.2707e-07, 1.1709e-07, 4.5032e-07, 8.6524e-12],\n",
      "        [1.9689e-10, 8.1756e-10, 1.0000e+00, 1.4681e-10, 3.5929e-09, 1.9708e-08,\n",
      "         2.8074e-09, 3.0324e-07, 1.0786e-07, 4.4538e-07, 8.7969e-12],\n",
      "        [1.9852e-10, 8.2823e-10, 1.0000e+00, 1.5090e-10, 3.7328e-09, 2.1063e-08,\n",
      "         2.8564e-09, 3.2680e-07, 1.0802e-07, 4.4518e-07, 9.3374e-12],\n",
      "        [1.6820e-10, 7.0151e-10, 1.0000e+00, 1.2135e-10, 3.3526e-09, 1.7979e-08,\n",
      "         2.3757e-09, 2.8061e-07, 9.8425e-08, 4.0504e-07, 7.8302e-12],\n",
      "        [1.8488e-10, 7.5458e-10, 1.0000e+00, 1.3439e-10, 3.3670e-09, 1.8269e-08,\n",
      "         2.6240e-09, 2.9631e-07, 1.0411e-07, 4.2585e-07, 8.1613e-12],\n",
      "        [1.8914e-10, 7.9643e-10, 1.0000e+00, 1.4503e-10, 3.6468e-09, 1.9077e-08,\n",
      "         2.7315e-09, 3.0968e-07, 1.1076e-07, 4.5603e-07, 8.8038e-12],\n",
      "        [1.9302e-10, 8.1130e-10, 1.0000e+00, 1.4447e-10, 3.8917e-09, 2.0410e-08,\n",
      "         2.9768e-09, 3.0211e-07, 1.1285e-07, 4.3894e-07, 9.5595e-12],\n",
      "        [1.9111e-10, 8.2290e-10, 1.0000e+00, 1.4382e-10, 3.7155e-09, 1.9440e-08,\n",
      "         2.8233e-09, 3.0746e-07, 1.0423e-07, 4.4572e-07, 8.7097e-12],\n",
      "        [1.8837e-10, 8.2395e-10, 1.0000e+00, 1.4064e-10, 3.6860e-09, 1.9232e-08,\n",
      "         2.7809e-09, 2.9680e-07, 1.0715e-07, 4.4020e-07, 8.7525e-12],\n",
      "        [1.7768e-10, 7.2330e-10, 1.0000e+00, 1.2564e-10, 3.3234e-09, 1.8062e-08,\n",
      "         2.4659e-09, 2.8820e-07, 1.0593e-07, 4.2236e-07, 7.7468e-12],\n",
      "        [1.6657e-10, 7.0592e-10, 1.0000e+00, 1.2537e-10, 3.2930e-09, 1.7980e-08,\n",
      "         2.4320e-09, 2.8579e-07, 1.0021e-07, 4.1398e-07, 7.1003e-12],\n",
      "        [2.2186e-10, 8.9947e-10, 1.0000e+00, 1.6186e-10, 4.1971e-09, 2.2133e-08,\n",
      "         3.0180e-09, 3.3666e-07, 1.2352e-07, 5.0725e-07, 9.6615e-12],\n",
      "        [1.8700e-10, 7.7242e-10, 1.0000e+00, 1.3943e-10, 3.3816e-09, 1.9182e-08,\n",
      "         2.6417e-09, 3.1759e-07, 1.0907e-07, 4.3990e-07, 8.0210e-12],\n",
      "        [1.9085e-10, 8.1170e-10, 1.0000e+00, 1.3654e-10, 3.4813e-09, 1.8894e-08,\n",
      "         2.7227e-09, 3.1169e-07, 1.1028e-07, 4.3973e-07, 8.4695e-12],\n",
      "        [2.6383e-10, 1.0962e-09, 1.0000e+00, 1.9600e-10, 4.8453e-09, 2.5805e-08,\n",
      "         3.5867e-09, 4.0662e-07, 1.3664e-07, 5.4885e-07, 1.2595e-11],\n",
      "        [2.0695e-10, 8.7044e-10, 1.0000e+00, 1.5351e-10, 4.0484e-09, 2.0385e-08,\n",
      "         2.9117e-09, 3.4286e-07, 1.1685e-07, 4.6565e-07, 9.4185e-12],\n",
      "        [1.7917e-10, 7.3400e-10, 1.0000e+00, 1.2999e-10, 3.4203e-09, 1.8810e-08,\n",
      "         2.4784e-09, 2.9204e-07, 1.0601e-07, 4.1802e-07, 8.0729e-12],\n",
      "        [1.8375e-10, 7.3416e-10, 1.0000e+00, 1.3473e-10, 3.4348e-09, 1.8820e-08,\n",
      "         2.6321e-09, 2.8219e-07, 1.0284e-07, 4.0829e-07, 8.2959e-12],\n",
      "        [1.7481e-10, 7.1260e-10, 1.0000e+00, 1.2709e-10, 3.3010e-09, 1.8048e-08,\n",
      "         2.5101e-09, 2.9328e-07, 1.0212e-07, 3.8541e-07, 7.4490e-12],\n",
      "        [1.7861e-10, 7.6301e-10, 1.0000e+00, 1.3380e-10, 3.4062e-09, 1.8125e-08,\n",
      "         2.6243e-09, 3.0218e-07, 1.0540e-07, 4.1807e-07, 8.1650e-12],\n",
      "        [1.9449e-10, 8.0482e-10, 1.0000e+00, 1.4585e-10, 3.6851e-09, 2.0188e-08,\n",
      "         2.7574e-09, 3.2683e-07, 1.1119e-07, 4.4510e-07, 9.1639e-12],\n",
      "        [2.0759e-10, 8.3641e-10, 1.0000e+00, 1.4414e-10, 3.5676e-09, 2.0905e-08,\n",
      "         2.6883e-09, 3.1999e-07, 1.1151e-07, 4.5583e-07, 8.8341e-12],\n",
      "        [2.0992e-10, 8.5590e-10, 1.0000e+00, 1.5459e-10, 3.9134e-09, 2.1417e-08,\n",
      "         2.9754e-09, 3.3011e-07, 1.1722e-07, 4.7326e-07, 9.7897e-12],\n",
      "        [2.1356e-10, 8.6597e-10, 1.0000e+00, 1.5202e-10, 3.8380e-09, 2.0896e-08,\n",
      "         2.8884e-09, 3.3633e-07, 1.1698e-07, 4.6149e-07, 8.8549e-12],\n",
      "        [1.7910e-10, 7.6259e-10, 1.0000e+00, 1.3196e-10, 3.4189e-09, 1.8380e-08,\n",
      "         2.6795e-09, 2.8620e-07, 1.0297e-07, 4.0701e-07, 8.1316e-12],\n",
      "        [1.8358e-10, 7.7822e-10, 1.0000e+00, 1.3838e-10, 3.5162e-09, 1.7846e-08,\n",
      "         2.6609e-09, 3.0556e-07, 1.0421e-07, 4.1774e-07, 7.7019e-12],\n",
      "        [2.0290e-10, 8.7244e-10, 1.0000e+00, 1.5078e-10, 3.9760e-09, 2.1245e-08,\n",
      "         2.9784e-09, 3.1468e-07, 1.1523e-07, 4.7658e-07, 9.1883e-12],\n",
      "        [1.8863e-10, 8.1317e-10, 1.0000e+00, 1.3835e-10, 3.6155e-09, 1.8691e-08,\n",
      "         2.5992e-09, 2.9529e-07, 1.0647e-07, 4.3028e-07, 8.0620e-12],\n",
      "        [1.8670e-10, 7.7013e-10, 1.0000e+00, 1.3570e-10, 3.4757e-09, 1.9329e-08,\n",
      "         2.5628e-09, 2.9106e-07, 1.0493e-07, 4.2563e-07, 8.3569e-12],\n",
      "        [1.7815e-10, 7.7351e-10, 1.0000e+00, 1.3175e-10, 3.5063e-09, 1.8985e-08,\n",
      "         2.6070e-09, 2.9338e-07, 1.0232e-07, 4.1634e-07, 7.9777e-12],\n",
      "        [2.2129e-10, 9.1447e-10, 1.0000e+00, 1.5971e-10, 4.0616e-09, 2.1828e-08,\n",
      "         2.9992e-09, 3.5238e-07, 1.2506e-07, 4.7658e-07, 9.9904e-12],\n",
      "        [2.2278e-10, 9.0165e-10, 1.0000e+00, 1.6150e-10, 3.9689e-09, 2.1274e-08,\n",
      "         2.9893e-09, 3.2176e-07, 1.2050e-07, 4.6651e-07, 9.9287e-12],\n",
      "        [1.8683e-10, 7.8680e-10, 1.0000e+00, 1.4315e-10, 3.5568e-09, 1.8651e-08,\n",
      "         2.7294e-09, 3.0231e-07, 1.0886e-07, 4.3315e-07, 8.2820e-12],\n",
      "        [1.5325e-10, 6.4073e-10, 1.0000e+00, 1.1521e-10, 2.9676e-09, 1.6042e-08,\n",
      "         2.1943e-09, 2.5313e-07, 9.1094e-08, 3.6672e-07, 6.4712e-12],\n",
      "        [2.3493e-10, 9.5810e-10, 1.0000e+00, 1.8075e-10, 4.4571e-09, 2.3036e-08,\n",
      "         3.2791e-09, 3.4365e-07, 1.2953e-07, 5.0451e-07, 1.0899e-11],\n",
      "        [2.5571e-10, 1.0712e-09, 1.0000e+00, 1.7493e-10, 4.4563e-09, 2.4440e-08,\n",
      "         3.3695e-09, 3.6433e-07, 1.3297e-07, 5.0509e-07, 1.1430e-11],\n",
      "        [2.1844e-10, 8.7755e-10, 1.0000e+00, 1.5498e-10, 3.9246e-09, 2.1463e-08,\n",
      "         3.1101e-09, 3.3703e-07, 1.1630e-07, 4.6610e-07, 9.9212e-12],\n",
      "        [1.8564e-10, 7.9227e-10, 1.0000e+00, 1.3916e-10, 3.6356e-09, 1.9166e-08,\n",
      "         2.7088e-09, 2.9881e-07, 1.0591e-07, 4.4089e-07, 8.6732e-12],\n",
      "        [1.6718e-10, 7.3934e-10, 1.0000e+00, 1.2170e-10, 3.2964e-09, 1.7405e-08,\n",
      "         2.4267e-09, 2.8662e-07, 9.9558e-08, 4.0195e-07, 7.2199e-12],\n",
      "        [1.8763e-10, 8.1082e-10, 1.0000e+00, 1.4053e-10, 3.6698e-09, 1.9269e-08,\n",
      "         2.7739e-09, 3.1111e-07, 1.0918e-07, 4.3274e-07, 8.4440e-12],\n",
      "        [1.8276e-10, 7.3902e-10, 1.0000e+00, 1.3194e-10, 3.4427e-09, 1.8852e-08,\n",
      "         2.6249e-09, 3.0310e-07, 1.0708e-07, 4.3015e-07, 8.1285e-12],\n",
      "        [1.8348e-10, 7.5948e-10, 1.0000e+00, 1.2974e-10, 3.5236e-09, 1.8469e-08,\n",
      "         2.5651e-09, 2.9457e-07, 1.0639e-07, 4.1676e-07, 8.0641e-12],\n",
      "        [1.5817e-10, 6.5301e-10, 1.0000e+00, 1.1436e-10, 3.0123e-09, 1.6465e-08,\n",
      "         2.2308e-09, 2.7385e-07, 9.5171e-08, 3.8691e-07, 6.9766e-12],\n",
      "        [1.6913e-10, 7.2699e-10, 1.0000e+00, 1.2706e-10, 3.3800e-09, 1.7765e-08,\n",
      "         2.4611e-09, 2.8618e-07, 1.0402e-07, 4.1156e-07, 7.8435e-12],\n",
      "        [1.8575e-10, 7.9035e-10, 1.0000e+00, 1.4192e-10, 3.4867e-09, 1.9306e-08,\n",
      "         2.7493e-09, 3.0355e-07, 1.0772e-07, 4.4369e-07, 8.5321e-12],\n",
      "        [1.7988e-10, 7.3317e-10, 1.0000e+00, 1.2830e-10, 3.4030e-09, 1.8303e-08,\n",
      "         2.4780e-09, 2.8490e-07, 1.0067e-07, 4.2678e-07, 7.8757e-12],\n",
      "        [1.9642e-10, 7.9368e-10, 1.0000e+00, 1.3761e-10, 3.6442e-09, 1.9496e-08,\n",
      "         2.6183e-09, 3.0236e-07, 1.0719e-07, 4.3302e-07, 8.3881e-12],\n",
      "        [2.3438e-10, 9.3809e-10, 1.0000e+00, 1.6867e-10, 4.1575e-09, 2.3838e-08,\n",
      "         3.2567e-09, 3.4603e-07, 1.1825e-07, 5.0395e-07, 1.0854e-11],\n",
      "        [1.8943e-10, 8.1540e-10, 1.0000e+00, 1.4095e-10, 3.5518e-09, 1.9296e-08,\n",
      "         2.7465e-09, 3.1713e-07, 1.0864e-07, 4.4715e-07, 8.6265e-12]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   8%|▊         | 6/72 [00:03<00:34,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels : torch.Size([64, 11])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predictions : torch.Size([64, 11])\n",
      "tensor([[6.2432e-08, 1.7481e-07, 9.9996e-01, 4.3358e-08, 5.6106e-07, 1.9496e-06,\n",
      "         4.0675e-07, 1.2419e-05, 7.3759e-06, 1.6427e-05, 6.3159e-09],\n",
      "        [9.3954e-10, 3.4844e-09, 1.0000e+00, 6.7828e-10, 1.4799e-08, 7.3264e-08,\n",
      "         1.0599e-08, 8.7994e-07, 3.5990e-07, 1.2116e-06, 5.3149e-11],\n",
      "        [3.3837e-10, 1.3577e-09, 1.0000e+00, 2.4695e-10, 6.0662e-09, 3.1759e-08,\n",
      "         4.4682e-09, 4.5917e-07, 1.7713e-07, 6.7586e-07, 1.6162e-11],\n",
      "        [2.4084e-10, 1.0117e-09, 1.0000e+00, 1.8303e-10, 4.5608e-09, 2.4552e-08,\n",
      "         3.4160e-09, 3.8276e-07, 1.3550e-07, 5.1953e-07, 1.0945e-11],\n",
      "        [2.6885e-10, 1.0508e-09, 1.0000e+00, 1.8827e-10, 4.7343e-09, 2.5253e-08,\n",
      "         3.5385e-09, 4.0984e-07, 1.4478e-07, 5.5134e-07, 1.1630e-11],\n",
      "        [2.2728e-10, 9.8102e-10, 1.0000e+00, 1.7288e-10, 4.5908e-09, 2.3379e-08,\n",
      "         3.3402e-09, 3.7407e-07, 1.3451e-07, 5.0936e-07, 1.0719e-11],\n",
      "        [1.8314e-10, 7.6807e-10, 1.0000e+00, 1.3474e-10, 3.4382e-09, 1.9775e-08,\n",
      "         2.7147e-09, 3.1742e-07, 1.1057e-07, 4.3222e-07, 8.0799e-12],\n",
      "        [2.7444e-10, 1.1325e-09, 1.0000e+00, 1.9960e-10, 4.8563e-09, 2.6037e-08,\n",
      "         3.7665e-09, 4.1107e-07, 1.4759e-07, 5.9894e-07, 1.2742e-11],\n",
      "        [1.7826e-10, 7.8018e-10, 1.0000e+00, 1.3271e-10, 3.6458e-09, 1.8829e-08,\n",
      "         2.6039e-09, 3.1270e-07, 1.1036e-07, 4.2554e-07, 8.2448e-12],\n",
      "        [2.6467e-10, 1.1099e-09, 1.0000e+00, 1.9741e-10, 5.0580e-09, 2.6193e-08,\n",
      "         3.7262e-09, 4.0064e-07, 1.4357e-07, 5.7481e-07, 1.2525e-11],\n",
      "        [2.0838e-10, 8.6270e-10, 1.0000e+00, 1.5148e-10, 3.7804e-09, 2.1308e-08,\n",
      "         2.9369e-09, 3.4327e-07, 1.2101e-07, 4.5549e-07, 9.2676e-12],\n",
      "        [1.9270e-10, 8.1445e-10, 1.0000e+00, 1.4533e-10, 3.7808e-09, 1.9861e-08,\n",
      "         2.8136e-09, 3.3066e-07, 1.2081e-07, 4.5258e-07, 8.7851e-12],\n",
      "        [2.0833e-10, 8.4371e-10, 1.0000e+00, 1.4944e-10, 3.8476e-09, 2.0308e-08,\n",
      "         2.8457e-09, 3.3714e-07, 1.1644e-07, 4.6224e-07, 9.0655e-12],\n",
      "        [2.8876e-10, 1.1924e-09, 1.0000e+00, 2.1387e-10, 5.3163e-09, 2.7092e-08,\n",
      "         3.9403e-09, 4.3267e-07, 1.5698e-07, 5.9759e-07, 1.3298e-11],\n",
      "        [2.2799e-10, 9.9308e-10, 1.0000e+00, 1.7113e-10, 4.2825e-09, 2.3187e-08,\n",
      "         3.1831e-09, 3.7608e-07, 1.3373e-07, 5.1578e-07, 1.0204e-11],\n",
      "        [2.0571e-10, 8.7819e-10, 1.0000e+00, 1.5760e-10, 3.9245e-09, 2.0737e-08,\n",
      "         2.9467e-09, 3.4628e-07, 1.2127e-07, 4.7750e-07, 9.5132e-12],\n",
      "        [2.3736e-10, 1.0255e-09, 1.0000e+00, 1.7752e-10, 4.6865e-09, 2.4025e-08,\n",
      "         3.4955e-09, 3.9306e-07, 1.3775e-07, 5.3301e-07, 1.1312e-11],\n",
      "        [2.0843e-10, 9.1588e-10, 1.0000e+00, 1.5971e-10, 4.1239e-09, 2.1282e-08,\n",
      "         3.0364e-09, 3.4811e-07, 1.2057e-07, 4.8639e-07, 9.8467e-12],\n",
      "        [2.2383e-10, 9.5621e-10, 1.0000e+00, 1.6803e-10, 4.2549e-09, 2.2789e-08,\n",
      "         3.1903e-09, 3.6479e-07, 1.3256e-07, 4.8914e-07, 1.0207e-11],\n",
      "        [1.9365e-10, 8.2605e-10, 1.0000e+00, 1.4425e-10, 3.6668e-09, 1.9544e-08,\n",
      "         2.7348e-09, 3.1584e-07, 1.1876e-07, 4.4837e-07, 8.6989e-12],\n",
      "        [1.9763e-10, 7.9640e-10, 1.0000e+00, 1.3836e-10, 3.6760e-09, 2.0010e-08,\n",
      "         2.8836e-09, 3.3374e-07, 1.1747e-07, 4.6966e-07, 8.4811e-12],\n",
      "        [2.2055e-10, 9.3881e-10, 1.0000e+00, 1.6091e-10, 4.0927e-09, 2.2504e-08,\n",
      "         3.1564e-09, 3.5275e-07, 1.2530e-07, 4.9792e-07, 1.0322e-11],\n",
      "        [2.1775e-10, 9.1501e-10, 1.0000e+00, 1.6573e-10, 4.1024e-09, 2.2174e-08,\n",
      "         3.1525e-09, 3.7653e-07, 1.2684e-07, 5.1257e-07, 9.7099e-12],\n",
      "        [2.3118e-10, 9.5517e-10, 1.0000e+00, 1.7173e-10, 4.2339e-09, 2.2403e-08,\n",
      "         3.3123e-09, 3.5980e-07, 1.3110e-07, 5.0647e-07, 1.0682e-11],\n",
      "        [2.4384e-10, 1.0232e-09, 1.0000e+00, 1.7864e-10, 4.7775e-09, 2.4350e-08,\n",
      "         3.4496e-09, 3.7933e-07, 1.3656e-07, 5.3296e-07, 1.1217e-11],\n",
      "        [2.3386e-10, 9.9859e-10, 1.0000e+00, 1.7507e-10, 4.5539e-09, 2.2575e-08,\n",
      "         3.3666e-09, 3.7220e-07, 1.3431e-07, 5.0435e-07, 1.1638e-11],\n",
      "        [2.8721e-10, 1.1588e-09, 1.0000e+00, 2.1296e-10, 5.0831e-09, 2.7396e-08,\n",
      "         3.7759e-09, 4.1473e-07, 1.4570e-07, 5.8631e-07, 1.3894e-11],\n",
      "        [2.1048e-10, 8.8243e-10, 1.0000e+00, 1.5886e-10, 4.0611e-09, 2.1087e-08,\n",
      "         3.0900e-09, 3.4127e-07, 1.2557e-07, 4.5605e-07, 9.3896e-12],\n",
      "        [2.6116e-10, 1.0694e-09, 1.0000e+00, 1.8652e-10, 4.9207e-09, 2.5528e-08,\n",
      "         3.5212e-09, 3.8393e-07, 1.4147e-07, 5.1755e-07, 1.2026e-11],\n",
      "        [2.1939e-10, 9.3181e-10, 1.0000e+00, 1.6542e-10, 4.1978e-09, 2.2455e-08,\n",
      "         3.1666e-09, 3.6220e-07, 1.2741e-07, 4.8881e-07, 1.0146e-11],\n",
      "        [2.4862e-10, 1.0370e-09, 1.0000e+00, 1.8261e-10, 4.5182e-09, 2.4722e-08,\n",
      "         3.4508e-09, 4.0943e-07, 1.3726e-07, 5.3629e-07, 1.1586e-11],\n",
      "        [1.9712e-10, 8.6615e-10, 1.0000e+00, 1.4833e-10, 3.8840e-09, 2.0910e-08,\n",
      "         2.8830e-09, 3.3201e-07, 1.1831e-07, 4.6053e-07, 9.1993e-12],\n",
      "        [2.1696e-10, 9.0013e-10, 1.0000e+00, 1.5541e-10, 4.0554e-09, 2.1345e-08,\n",
      "         3.0698e-09, 3.4196e-07, 1.2485e-07, 4.7715e-07, 9.7412e-12],\n",
      "        [2.0595e-10, 9.0011e-10, 1.0000e+00, 1.4828e-10, 3.9781e-09, 2.0633e-08,\n",
      "         2.8731e-09, 3.4458e-07, 1.1652e-07, 4.7351e-07, 9.2118e-12],\n",
      "        [2.6488e-10, 1.0975e-09, 1.0000e+00, 1.9539e-10, 4.9660e-09, 2.5946e-08,\n",
      "         3.6926e-09, 4.0444e-07, 1.4869e-07, 5.6849e-07, 1.2263e-11],\n",
      "        [2.5394e-10, 1.0210e-09, 1.0000e+00, 1.8247e-10, 4.4677e-09, 2.4587e-08,\n",
      "         3.4118e-09, 3.8749e-07, 1.3577e-07, 5.3423e-07, 1.1688e-11],\n",
      "        [2.4968e-10, 1.0691e-09, 1.0000e+00, 1.8349e-10, 4.5968e-09, 2.4323e-08,\n",
      "         3.4913e-09, 3.7587e-07, 1.3870e-07, 5.2799e-07, 1.1488e-11],\n",
      "        [2.8058e-10, 1.1836e-09, 1.0000e+00, 2.1762e-10, 5.2768e-09, 2.6852e-08,\n",
      "         4.0539e-09, 4.2782e-07, 1.5782e-07, 5.8975e-07, 1.3156e-11],\n",
      "        [2.2210e-10, 8.9361e-10, 1.0000e+00, 1.6279e-10, 4.3433e-09, 2.3579e-08,\n",
      "         3.2215e-09, 3.6485e-07, 1.2867e-07, 5.0404e-07, 1.0154e-11],\n",
      "        [2.2751e-10, 8.8096e-10, 1.0000e+00, 1.5760e-10, 4.0486e-09, 2.1645e-08,\n",
      "         3.1692e-09, 3.6518e-07, 1.2290e-07, 5.0030e-07, 1.0202e-11],\n",
      "        [2.7320e-10, 1.1006e-09, 1.0000e+00, 2.0101e-10, 5.0600e-09, 2.6813e-08,\n",
      "         3.7867e-09, 4.1096e-07, 1.4607e-07, 5.6367e-07, 1.2652e-11],\n",
      "        [2.4486e-10, 1.0051e-09, 1.0000e+00, 1.7286e-10, 4.4581e-09, 2.4347e-08,\n",
      "         3.3046e-09, 3.8320e-07, 1.3125e-07, 5.2814e-07, 1.0874e-11],\n",
      "        [2.2538e-10, 9.0447e-10, 1.0000e+00, 1.5930e-10, 4.1037e-09, 2.1563e-08,\n",
      "         3.0230e-09, 3.4690e-07, 1.2664e-07, 4.9317e-07, 9.5512e-12],\n",
      "        [2.2727e-10, 9.6377e-10, 1.0000e+00, 1.7633e-10, 4.3193e-09, 2.3603e-08,\n",
      "         3.3501e-09, 3.7262e-07, 1.3332e-07, 5.0645e-07, 1.1175e-11],\n",
      "        [2.0484e-10, 8.6356e-10, 1.0000e+00, 1.5529e-10, 3.9739e-09, 2.0694e-08,\n",
      "         2.9512e-09, 3.3340e-07, 1.2795e-07, 4.9432e-07, 9.4617e-12],\n",
      "        [2.5684e-10, 1.0360e-09, 1.0000e+00, 1.9789e-10, 4.8206e-09, 2.5332e-08,\n",
      "         3.5528e-09, 4.2029e-07, 1.4800e-07, 5.5343e-07, 1.1980e-11],\n",
      "        [2.4178e-10, 9.7834e-10, 1.0000e+00, 1.7720e-10, 4.5483e-09, 2.3788e-08,\n",
      "         3.3432e-09, 3.9160e-07, 1.4036e-07, 5.5044e-07, 1.0398e-11],\n",
      "        [2.0403e-10, 8.5977e-10, 1.0000e+00, 1.5231e-10, 3.8350e-09, 2.0614e-08,\n",
      "         2.8787e-09, 3.4444e-07, 1.1921e-07, 4.6484e-07, 8.7311e-12],\n",
      "        [2.6538e-10, 1.0708e-09, 1.0000e+00, 1.9204e-10, 4.7946e-09, 2.5944e-08,\n",
      "         3.5758e-09, 4.0658e-07, 1.4893e-07, 5.6110e-07, 1.2077e-11],\n",
      "        [2.1754e-10, 9.1275e-10, 1.0000e+00, 1.6952e-10, 4.1891e-09, 2.2841e-08,\n",
      "         3.1013e-09, 3.6747e-07, 1.2855e-07, 5.2165e-07, 1.0146e-11],\n",
      "        [1.9673e-10, 8.3337e-10, 1.0000e+00, 1.4668e-10, 3.6995e-09, 2.0207e-08,\n",
      "         2.7371e-09, 3.2804e-07, 1.1836e-07, 4.5880e-07, 8.8853e-12],\n",
      "        [2.2982e-10, 9.8987e-10, 1.0000e+00, 1.7827e-10, 4.4719e-09, 2.2711e-08,\n",
      "         3.2790e-09, 3.7610e-07, 1.3421e-07, 5.2015e-07, 1.1203e-11],\n",
      "        [2.3266e-10, 9.9789e-10, 1.0000e+00, 1.7864e-10, 4.4552e-09, 2.2647e-08,\n",
      "         3.2321e-09, 3.7410e-07, 1.3060e-07, 4.9366e-07, 1.1072e-11],\n",
      "        [2.5736e-10, 1.0528e-09, 1.0000e+00, 1.8759e-10, 4.7149e-09, 2.4902e-08,\n",
      "         3.5609e-09, 4.0666e-07, 1.3901e-07, 5.5356e-07, 1.1742e-11],\n",
      "        [2.1563e-10, 9.1848e-10, 1.0000e+00, 1.6042e-10, 4.1681e-09, 2.1285e-08,\n",
      "         3.0348e-09, 3.4517e-07, 1.2640e-07, 4.8160e-07, 9.8811e-12],\n",
      "        [2.6281e-10, 1.0796e-09, 1.0000e+00, 1.9103e-10, 4.7721e-09, 2.5603e-08,\n",
      "         3.7001e-09, 4.0009e-07, 1.4441e-07, 5.4956e-07, 1.2159e-11],\n",
      "        [2.1725e-10, 9.1798e-10, 1.0000e+00, 1.6480e-10, 4.2161e-09, 2.1197e-08,\n",
      "         3.1533e-09, 3.5887e-07, 1.2403e-07, 4.8125e-07, 9.8854e-12],\n",
      "        [2.2102e-10, 9.0809e-10, 1.0000e+00, 1.6109e-10, 3.9593e-09, 2.2139e-08,\n",
      "         3.1493e-09, 3.5220e-07, 1.2535e-07, 4.5700e-07, 1.0322e-11],\n",
      "        [2.0497e-10, 8.4837e-10, 1.0000e+00, 1.4991e-10, 3.7615e-09, 2.0153e-08,\n",
      "         2.9340e-09, 3.3761e-07, 1.1420e-07, 4.6116e-07, 9.1721e-12],\n",
      "        [2.2036e-10, 9.1090e-10, 1.0000e+00, 1.6362e-10, 4.0532e-09, 2.1573e-08,\n",
      "         3.0830e-09, 3.5981e-07, 1.2774e-07, 5.2179e-07, 9.5737e-12],\n",
      "        [2.7504e-10, 1.1169e-09, 1.0000e+00, 2.0166e-10, 4.8776e-09, 2.5554e-08,\n",
      "         3.6589e-09, 4.1243e-07, 1.4887e-07, 5.9499e-07, 1.2312e-11],\n",
      "        [2.1142e-10, 8.8052e-10, 1.0000e+00, 1.5936e-10, 3.8718e-09, 2.1071e-08,\n",
      "         3.0234e-09, 3.4787e-07, 1.2288e-07, 4.8374e-07, 9.4375e-12],\n",
      "        [2.7191e-10, 1.0864e-09, 1.0000e+00, 1.9913e-10, 4.7435e-09, 2.5641e-08,\n",
      "         3.7287e-09, 3.9723e-07, 1.4320e-07, 5.6685e-07, 1.2502e-11],\n",
      "        [2.4800e-10, 9.9637e-10, 1.0000e+00, 1.8312e-10, 4.5109e-09, 2.3934e-08,\n",
      "         3.4567e-09, 3.8079e-07, 1.3618e-07, 5.2902e-07, 1.0889e-11]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   8%|▊         | 6/72 [00:03<00:37,  1.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_823/3608949282.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_mean_count_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training loop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0maudios\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# one hot encode labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x7fa3a0a2d5e0> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved code: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface_queue.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "model.to(\"cuda\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # -------------------------------- Train loop -------------------------------- #\n",
    "    train_mean_loss = 0\n",
    "    train_mean_count_loss = 0\n",
    "    for d in tqdm(train_loader, \"training loop\"):\n",
    "        audios = d[0].to(\"cuda\")\n",
    "        labels = d[1]\n",
    "        # one hot encode labels\n",
    "        count_labels = labels.sum(axis=1)\n",
    "        one_hot_label = torch.eye(11)[count_labels].to(\"cuda\")\n",
    "        # forward pass\n",
    "        predictions = model.forward(audios)\n",
    "        # count loss\n",
    "        count_loss_value = loss(predictions, one_hot_label)\n",
    "        train_mean_count_loss += count_loss_value.item()\n",
    "        #optimize\n",
    "        optimizer.zero_grad()\n",
    "        count_loss_value.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch {}/{}\".format(epoch+1, EPOCHS))\n",
    "    print(\"Train count Loss : {:.4f}\".format(train_mean_count_loss/len(train_loader)))\n",
    "    log = {\n",
    "        \"MAE_train_count_loss\":train_mean_count_loss/len(train_loader),\n",
    "        \"epoch\":epoch\n",
    "        }\n",
    "    # --------------------------------- Eval loop -------------------------------- #\n",
    "    if (epoch+1)%EVAL_EACH == 0:\n",
    "        val_mean_loss = 0\n",
    "        val_mean_count_loss = 0\n",
    "        model.eval()\n",
    "        for d in tqdm(val_loader, \"evaluation loop\"):\n",
    "            audios = d[0].to(\"cuda\")\n",
    "            labels = d[1]\n",
    "            # one hot encode labels\n",
    "            count_labels = labels.sum(axis=1)\n",
    "            one_hot_label = torch.eye(11)[count_labels].to(\"cuda\")\n",
    "            # forward pass\n",
    "            predictions = model.forward(audios)\n",
    "            # count loss\n",
    "            count_loss_value = loss(predictions, one_hot_label)\n",
    "            val_mean_count_loss += count_loss_value.item()\n",
    "        model.train()\n",
    "        log[\"MAE_val_count_loss\"] = val_mean_count_loss/len(val_loader)\n",
    "        print(\"validation count Loss : {:.4f}\".format(val_mean_count_loss/len(val_loader)))\n",
    "        \n",
    "    wandb.log(log)\n",
    "    # wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._resume_backend at 0x7fa3a0a2d310> (for pre_run_cell):\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_resume_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jupyter_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface_queue.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x7fa3a0a2d5e0> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved code: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface_queue.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread ChkStopThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "Exception in thread NetStatThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "        self.run()\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/threading.py\", line 910, in run\n",
      "self.run()\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 148, in check_network_status\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 166, in check_status\n",
      "    status_response = self._interface.communicate_network_status()\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface.py\", line 125, in communicate_network_status\n",
      "    status_response = self._interface.communicate_stop_status()\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface.py\", line 114, in communicate_stop_status\n",
      "        resp = self._communicate_stop_status(status)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 378, in _communicate_stop_status\n",
      "resp = self._communicate_network_status(status)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 388, in _communicate_network_status\n",
      "        resp = self._communicate(req, local=True)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 213, in _communicate\n",
      "resp = self._communicate(req, local=True)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 213, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 218, in _communicate_async\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 218, in _communicate_async\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34a01c7cbd4d230e2daaa44d8acb4ab26fe27453faf910e8270bab9ecc3bb26f"
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
