{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets place this notebook in the root directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = %pwd\n",
    "if path.split(os.sep)[-1] == 'notebooks':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also refresh all our dependecies in run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load environment variables, if they exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env_consts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------- torch stuff ------------------------------- #\n",
    "import torch\n",
    "\n",
    "# ----------------------------------- other ---------------------------------- #\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "# ---------------------------------- Custom ---------------------------------- #\n",
    "from src.load_dataset import get_splitter_dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs :  {'BATCH_SIZE': 8, 'TRAIN_SPLIT': 0.8, 'FTYPE': torch.float32, 'cache': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching dataset: 100%|██████████| 5720/5720 [00:53<00:00, 107.84it/s]\n"
     ]
    }
   ],
   "source": [
    "F16 = torch.float16\n",
    "F32 = torch.float32\n",
    "F64 = torch.float64\n",
    "FTYPE = F32\n",
    "TRAIN_SPLIT = float(os.getenv('KLEE_TRAIN_SPLIT', 0.8))\n",
    "BATCH_SIZE = int(os.getenv('KLEE_BATCH_SIZE', 64))\n",
    "kwargs = {\n",
    "        \"BATCH_SIZE\": BATCH_SIZE,\n",
    "        \"TRAIN_SPLIT\": TRAIN_SPLIT,\n",
    "        \"FTYPE\": FTYPE,\n",
    "        \"cache\": True,\n",
    "        }\n",
    "print(\"kwargs : \",kwargs)\n",
    "train_loader, val_loader = get_splitter_dataloaders(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3jvdr84m) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4774... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f736f149324a3ca590b7b76091e067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">wise-tree-33</strong>: <a href=\"https://wandb.ai/mustapha/klee_project_audio/runs/3jvdr84m\" target=\"_blank\">https://wandb.ai/mustapha/klee_project_audio/runs/3jvdr84m</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220211_165320-3jvdr84m/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3jvdr84m). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/mustapha/klee_project_audio/runs/3623t2ra\" target=\"_blank\">splendid-breeze-34</a></strong> to <a href=\"https://wandb.ai/mustapha/klee_project_audio\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/mustapha/klee_project_audio/runs/3623t2ra?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff1fc929f70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"klee_project_audio\", entity=\"mustapha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch sequential\n",
    "c_1 = 64\n",
    "kernel_1 = 21\n",
    "c_2 = 64\n",
    "kernel_2 = 7\n",
    "kernel_pool = 3\n",
    "\n",
    "c_3 = 128\n",
    "kernel_3 = 3\n",
    "c_4 = 256\n",
    "kernel_4 = 3\n",
    "\n",
    "dropout = 0.1\n",
    "model = torch.nn.Sequential( #input size = 80000\n",
    "    torch.nn.Conv1d(1, c_1, kernel_1, stride=5, dtype=FTYPE),\n",
    "    torch.nn.Conv1d(c_1, c_2, kernel_2, dtype=FTYPE),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(dropout),\n",
    "    torch.nn.MaxPool1d(kernel_pool),\n",
    "    \n",
    "    torch.nn.Conv1d(c_2, c_3, kernel_3, dtype=FTYPE),\n",
    "    torch.nn.Conv1d(c_3, c_4, kernel_4, dtype=FTYPE),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(dropout),\n",
    "    torch.nn.MaxPool1d(kernel_pool),\n",
    "    \n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(c_4*1775, 2, dtype=FTYPE),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-2\n",
    "EPOCHS = 700\n",
    "MODEL_DROPOUT = dropout\n",
    "OPTIMIZER_L2 = 0.001\n",
    "OPTIMIZER_MOM = 0.9\n",
    "SCHEDULER_PATIENCE = 10\n",
    "SCHEDULER_FACTOR = 0.5\n",
    "SCHEDULER_MIN_LR = 1e-4\n",
    "CLIP_GRAD = 1e10\n",
    "EVAL_EACH = 10\n",
    "\n",
    "wandb.config.update({\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"MODEL_DROPOUT\": MODEL_DROPOUT,\n",
    "    \"OPTIMIZER\": \"SGD\",\n",
    "    \"OPTIMIZER_L2\":OPTIMIZER_L2,\n",
    "    \"OPTIMIZER_MOM\": OPTIMIZER_MOM,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"SCHEDULER\": \"ReduceLROnPlateau\",\n",
    "    \"SCHEDULER_PATIENCE\": SCHEDULER_PATIENCE,\n",
    "    \"SCHEDULER_FACTOR\": SCHEDULER_FACTOR,\n",
    "    \"SCHEDULER_MIN_LR\": SCHEDULER_MIN_LR,\n",
    "    \"CLIP_GRAD\": CLIP_GRAD,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   0%|          | 0/572 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4432/1178904403.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mcount_loss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mCLIP_GRAD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP_GRAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/series_forcasting/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, weight_decay=OPTIMIZER_L2, momentum=OPTIMIZER_MOM)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=SCHEDULER_PATIENCE, factor=SCHEDULER_FACTOR,min_lr=SCHEDULER_MIN_LR)\n",
    "\n",
    "model.to(\"cuda\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # -------------------------------- Train loop -------------------------------- #\n",
    "    train_mean_loss = 0\n",
    "    train_mean_count_loss = 0\n",
    "    for d in tqdm(train_loader, \"training loop\"):\n",
    "        audios = d[0].to(\"cuda\")\n",
    "        labels = d[1].to(\"cuda\")\n",
    "        predictions = model.forward(audios)\n",
    "        # gender loss\n",
    "        loss_value = loss(predictions, labels)\n",
    "        train_mean_loss += loss_value.item()\n",
    "        # count loss\n",
    "        count_loss_value = loss(predictions.sum(axis=1), labels.sum(axis=1))\n",
    "        train_mean_count_loss += count_loss_value.item()\n",
    "        #optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss_value.backward(retain_graph=True)\n",
    "        count_loss_value.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), -CLIP_GRAD, CLIP_GRAD)\n",
    "        optimizer.step()\n",
    "    scheduler.step(train_mean_loss/len(train_loader))\n",
    "    print(\"Epoch {}/{}\".format(epoch+1, EPOCHS))\n",
    "    print(\"Train Loss : {:.4f}\".format(train_mean_loss/len(train_loader)), end=\"\\t\")\n",
    "    print(\"Train count Loss : {:.4f}\".format(train_mean_count_loss/len(train_loader)))\n",
    "    log = {\n",
    "        \"train_loss\":train_mean_loss/len(train_loader),\n",
    "        \"count_loss\":train_mean_count_loss/len(train_loader),\n",
    "        \"epoch\":epoch, \n",
    "        \"next_lr\" :scheduler.state_dict()[\"_last_lr\"][0]\n",
    "        }\n",
    "    # --------------------------------- Eval loop -------------------------------- #\n",
    "    if (epoch+1)%EVAL_EACH == 0:\n",
    "        val_mean_loss = 0\n",
    "        val_mean_count_loss = 0\n",
    "        model.eval()\n",
    "        for d in tqdm(val_loader, \"evaluation loop\"):\n",
    "            audios = d[0].to(\"cuda\")\n",
    "            labels = d[1].to(\"cuda\")\n",
    "            predictions = model.forward(audios)\n",
    "            # gender loss\n",
    "            loss_value = loss(predictions, labels)\n",
    "            val_mean_loss += loss_value.item()\n",
    "            # count loss\n",
    "            count_loss_value = loss(predictions.sum(axis=1), labels.sum(axis=1))\n",
    "            val_mean_count_loss += count_loss_value.item()\n",
    "        model.train()\n",
    "        log[\"val_loss\"] = val_mean_loss/len(val_loader)\n",
    "        log[\"val_count_loss\"] = val_mean_count_loss/len(val_loader)\n",
    "        print(\"validation Loss : {:.4f}\".format(val_mean_loss/len(val_loader)), end=\"\\t\")\n",
    "        print(\"validation count Loss : {:.4f}\".format(val_mean_count_loss/len(val_loader)))\n",
    "        \n",
    "    wandb.log(log)\n",
    "    # wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34a01c7cbd4d230e2daaa44d8acb4ab26fe27453faf910e8270bab9ecc3bb26f"
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
