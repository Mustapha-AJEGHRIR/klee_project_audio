{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To refresh imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------- torch stuff ------------------------------- #\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# ----------------------------------- other ---------------------------------- #\n",
    "from glob import glob\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile\n",
    "import json\n",
    "import os\n",
    "\n",
    "# ---------------------------------- Custom ---------------------------------- #\n",
    "from utils.precision_loss import show_sum_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why using scipy.io instead soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soundfile converts directly to float 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.0944519 ,  0.09963989,  0.13208008, ..., -0.05599976,\n",
       "       -0.04922485, -0.03912354])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"soundfile converts directly to float 64\")\n",
    "sf.read(\"../data/LibriCount/10_85b5ac.wav\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wavfile concervs the original format : int16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3095,  3265,  4328, ..., -1835, -1613, -1282], dtype=int16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"wavfile concervs the original format : int16\")\n",
    "wavfile.read(\"../data/LibriCount/10_85b5ac.wav\")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "F16 = torch.float16\n",
    "F32 = torch.float32\n",
    "F64 = torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion Errors from int16 in range(-32768, 32768) maxed by (max is=) :\n",
      "\tFloat 16  8.0\n",
      "\tFloat 32  0.0\n",
      "\tFloat 64  0.0\n"
     ]
    }
   ],
   "source": [
    "show_sum_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/LibriCount\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioCountGender(Dataset):\n",
    "    def __init__(self, data_dir=data_dir, dtype = F16):\n",
    "        self.sounds = glob(os.path.join(data_dir,\"*.wav\"))\n",
    "        self.labels = glob(os.path.join(data_dir,\"*.json\"))\n",
    "        self.dtype = dtype\n",
    "    def __getitem__(self, index):\n",
    "        # clip, sample_rate = sf.read(self.sounds[index])\n",
    "        sample_rate, clip = wavfile.read(self.sounds[index])\n",
    "        with open(self.labels[index]) as f:\n",
    "            label = json.load(f)\n",
    "        genders = [0, 0] #[Male, Female]\n",
    "        for person in label:\n",
    "            gender = person[\"sex\"]\n",
    "            if gender == \"F\":\n",
    "                genders[1] += 1\n",
    "            else :\n",
    "                genders[0] += 1\n",
    "        return torch.tensor(clip, dtype=self.dtype), torch.tensor(genders)\n",
    "    def __len__(self):\n",
    "        return len(self.sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3096.,  3264.,  4328.,  ..., -1835., -1613., -1282.],\n",
       "        dtype=torch.float16),\n",
       " tensor([3, 7]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = AudioCountGender()\n",
    "data[800]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=data, batch_size=64, shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_64_24_\n",
      "Duration: 50.47s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "L = []\n",
    "start = time()\n",
    "for d in dataloader:\n",
    "    L.append(d)\n",
    "    print(len(d[0]), end=\"_\")\n",
    "end = time()\n",
    "print()\n",
    "print(\"Duration: {:.2f}s\".format(end-start))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34a01c7cbd4d230e2daaa44d8acb4ab26fe27453faf910e8270bab9ecc3bb26f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('series_forcasting')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
